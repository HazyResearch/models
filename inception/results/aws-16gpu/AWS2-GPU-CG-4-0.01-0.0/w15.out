I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['master:2200']
INFO:tensorflow:Worker hosts are: ['master:2201', 'master:2202', 'master:2203', 'master:2204', 'node001:2205', 'node001:2206', 'node001:2207', 'node001:2208', 'node002:2209', 'node002:2210', 'node002:2211', 'node002:2212', 'node003:2213', 'node003:2214', 'node003:2215', 'node003:2216']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:05.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:784] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:05.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {master:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {master:2201, master:2202, master:2203, master:2204, node001:2205, node001:2206, node001:2207, node001:2208, node002:2209, node002:2210, node002:2211, node002:2212, node003:2213, node003:2214, localhost:2215, node003:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2215
INFO:tensorflow:Learning rate: 0.010000, momentum: 0.000000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 4
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 4
INFO:tensorflow:Tokens per step: 4
INFO:tensorflow:2016-08-09 13:42:21.905205 Supervisor
INFO:tensorflow:got sessions! 2016-08-09 13:42:39.846974 
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=2855 evicted_count=1000 eviction_rate=0.350263 and unsatisfied allocation rate=0.534236
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Loss: 5.399961, time: 15.789 sec/batch
INFO:tensorflow:Step: 399, Loss: 5.219645, time: 2.907 sec/batch
INFO:tensorflow:Step: 399, Loss: 5.485578, time: 6.788 sec/batch
INFO:tensorflow:Step: 402, Loss: 5.184768, time: 13.046 sec/batch
INFO:tensorflow:Step: 409, Loss: 5.193606, time: 6.209 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 412, Loss: 5.675901, time: 5.898 sec/batch
INFO:tensorflow:Step: 417, Loss: 5.581060, time: 4.706 sec/batch
INFO:tensorflow:Step: 421, Loss: 5.257062, time: 6.093 sec/batch
INFO:tensorflow:Step: 424, Loss: 5.241753, time: 4.485 sec/batch
INFO:tensorflow:Step: 428, Loss: 5.400200, time: 4.241 sec/batch
INFO:tensorflow:Step: 432, Loss: 5.241473, time: 4.447 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4060 evicted_count=2000 eviction_rate=0.492611 and unsatisfied allocation rate=0.459926
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 281 to 309
INFO:tensorflow:Step: 436, Loss: 5.356567, time: 4.056 sec/batch
INFO:tensorflow:Step: 440, Loss: 5.441068, time: 4.379 sec/batch
INFO:tensorflow:Step: 444, Loss: 5.233354, time: 4.583 sec/batch
INFO:tensorflow:Step: 446, Loss: 5.036584, time: 3.582 sec/batch
INFO:tensorflow:Step: 450, Loss: 5.145215, time: 4.702 sec/batch
INFO:tensorflow:Step: 454, Loss: 5.345466, time: 3.610 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1049 evicted_count=1000 eviction_rate=0.953289 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 457, Loss: 5.511880, time: 3.760 sec/batch
INFO:tensorflow:Step: 461, Loss: 5.276808, time: 4.416 sec/batch
INFO:tensorflow:Step: 465, Loss: 5.974702, time: 3.594 sec/batch
INFO:tensorflow:Step: 469, Loss: 5.044675, time: 4.002 sec/batch
INFO:tensorflow:Step: 473, Loss: 5.055997, time: 4.095 sec/batch
INFO:tensorflow:Step: 477, Loss: 5.162212, time: 4.670 sec/batch
INFO:tensorflow:Step: 481, Loss: 5.258326, time: 3.877 sec/batch
INFO:tensorflow:Step: 485, Loss: 5.143126, time: 4.071 sec/batch
INFO:tensorflow:Step: 489, Loss: 5.313500, time: 4.528 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4015 evicted_count=1000 eviction_rate=0.249066 and unsatisfied allocation rate=0.227707
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:Step: 494, Loss: 5.171144, time: 3.437 sec/batch
INFO:tensorflow:Step: 497, Loss: 5.234125, time: 3.846 sec/batch
INFO:tensorflow:Step: 501, Loss: 5.276993, time: 3.787 sec/batch
INFO:tensorflow:Step: 505, Loss: 5.255152, time: 3.826 sec/batch
INFO:tensorflow:Step: 509, Loss: 5.163842, time: 4.354 sec/batch
INFO:tensorflow:Step: 513, Loss: 5.197864, time: 3.473 sec/batch
INFO:tensorflow:Step: 517, Loss: 5.080810, time: 4.364 sec/batch
INFO:tensorflow:Step: 521, Loss: 5.166960, time: 3.922 sec/batch
INFO:tensorflow:Step: 525, Loss: 5.738811, time: 4.416 sec/batch
INFO:tensorflow:Step: 529, Loss: 5.164422, time: 3.796 sec/batch
INFO:tensorflow:Step: 533, Loss: 5.255825, time: 4.611 sec/batch
INFO:tensorflow:Step: 537, Loss: 5.053401, time: 4.736 sec/batch
INFO:tensorflow:Step: 541, Loss: 5.350840, time: 3.420 sec/batch
INFO:tensorflow:Step: 545, Loss: 5.146374, time: 4.138 sec/batch
INFO:tensorflow:Step: 549, Loss: 5.112641, time: 4.587 sec/batch
INFO:tensorflow:Step: 553, Loss: 5.064408, time: 4.512 sec/batch
INFO:tensorflow:Step: 557, Loss: 5.144318, time: 4.187 sec/batch
INFO:tensorflow:Step: 561, Loss: 5.324418, time: 3.924 sec/batch
INFO:tensorflow:Step: 564, Loss: 5.093650, time: 3.712 sec/batch
INFO:tensorflow:Step: 568, Loss: 4.961781, time: 3.917 sec/batch
INFO:tensorflow:Step: 572, Loss: 4.910300, time: 4.688 sec/batch
INFO:tensorflow:Step: 577, Loss: 5.316581, time: 3.818 sec/batch
INFO:tensorflow:Step: 580, Loss: 5.175013, time: 3.401 sec/batch
INFO:tensorflow:Step: 584, Loss: 4.944164, time: 3.428 sec/batch
INFO:tensorflow:Step: 588, Loss: 4.859211, time: 3.661 sec/batch
INFO:tensorflow:Step: 592, Loss: 5.010445, time: 3.510 sec/batch
INFO:tensorflow:Step: 596, Loss: 5.168727, time: 3.586 sec/batch
INFO:tensorflow:Step: 600, Loss: 5.267003, time: 4.397 sec/batch
INFO:tensorflow:Step: 604, Loss: 5.123003, time: 4.598 sec/batch
INFO:tensorflow:Step: 608, Loss: 5.089621, time: 4.807 sec/batch
INFO:tensorflow:Step: 613, Loss: 5.025212, time: 3.310 sec/batch
INFO:tensorflow:Step: 617, Loss: 5.218302, time: 3.859 sec/batch
INFO:tensorflow:Step: 620, Loss: 4.996353, time: 4.278 sec/batch
INFO:tensorflow:Step: 624, Loss: 5.180370, time: 3.564 sec/batch
INFO:tensorflow:Step: 628, Loss: 5.171546, time: 3.259 sec/batch
INFO:tensorflow:Step: 632, Loss: 5.178443, time: 4.211 sec/batch
INFO:tensorflow:Step: 636, Loss: 4.959497, time: 4.439 sec/batch
INFO:tensorflow:Step: 640, Loss: 5.246159, time: 4.227 sec/batch
INFO:tensorflow:Step: 644, Loss: 4.953100, time: 4.624 sec/batch
INFO:tensorflow:Step: 647, Loss: 5.100592, time: 4.291 sec/batch
INFO:tensorflow:Step: 651, Loss: 5.229767, time: 4.033 sec/batch
INFO:tensorflow:Step: 655, Loss: 4.986043, time: 4.103 sec/batch
INFO:tensorflow:Step: 659, Loss: 4.935378, time: 4.568 sec/batch
INFO:tensorflow:Step: 664, Loss: 4.875189, time: 3.573 sec/batch
INFO:tensorflow:Step: 668, Loss: 4.803388, time: 3.947 sec/batch
INFO:tensorflow:Step: 672, Loss: 5.259376, time: 4.043 sec/batch
INFO:tensorflow:Step: 676, Loss: 5.028376, time: 4.572 sec/batch
INFO:tensorflow:Step: 680, Loss: 5.099422, time: 3.925 sec/batch
INFO:tensorflow:Step: 684, Loss: 5.047111, time: 4.129 sec/batch
INFO:tensorflow:Step: 688, Loss: 4.968345, time: 4.071 sec/batch
INFO:tensorflow:Step: 692, Loss: 4.916120, time: 4.094 sec/batch
INFO:tensorflow:Step: 696, Loss: 4.972462, time: 4.931 sec/batch
INFO:tensorflow:Step: 700, Loss: 4.782053, time: 5.611 sec/batch
INFO:tensorflow:Step: 706, Loss: 5.044784, time: 4.010 sec/batch
INFO:tensorflow:Step: 708, Loss: 5.122150, time: 3.705 sec/batch
INFO:tensorflow:Step: 712, Loss: 4.851580, time: 3.518 sec/batch
INFO:tensorflow:Step: 716, Loss: 5.031526, time: 4.232 sec/batch
INFO:tensorflow:Step: 720, Loss: 4.756747, time: 4.757 sec/batch
INFO:tensorflow:Step: 724, Loss: 5.013057, time: 4.720 sec/batch
INFO:tensorflow:Step: 728, Loss: 5.267071, time: 3.916 sec/batch
INFO:tensorflow:Step: 732, Loss: 4.784032, time: 3.880 sec/batch
INFO:tensorflow:Step: 736, Loss: 5.179630, time: 4.839 sec/batch
INFO:tensorflow:Step: 740, Loss: 4.795868, time: 3.719 sec/batch
INFO:tensorflow:Step: 744, Loss: 4.955128, time: 3.237 sec/batch
INFO:tensorflow:Step: 748, Loss: 4.890845, time: 4.202 sec/batch
INFO:tensorflow:Step: 752, Loss: 4.855487, time: 4.278 sec/batch
INFO:tensorflow:Step: 756, Loss: 4.852680, time: 4.024 sec/batch
INFO:tensorflow:Step: 760, Loss: 5.043557, time: 4.014 sec/batch
INFO:tensorflow:Step: 764, Loss: 5.020082, time: 3.636 sec/batch
INFO:tensorflow:Step: 768, Loss: 4.843978, time: 4.244 sec/batch
INFO:tensorflow:Step: 772, Loss: 5.246163, time: 4.248 sec/batch
INFO:tensorflow:Step: 776, Loss: 5.066630, time: 4.070 sec/batch
INFO:tensorflow:Step: 780, Loss: 5.320835, time: 3.953 sec/batch
INFO:tensorflow:Step: 784, Loss: 4.886445, time: 4.118 sec/batch
INFO:tensorflow:Step: 788, Loss: 4.637802, time: 3.596 sec/batch
INFO:tensorflow:Step: 792, Loss: 4.861832, time: 3.824 sec/batch
INFO:tensorflow:Step: 796, Loss: 5.160812, time: 4.558 sec/batch
INFO:tensorflow:Step: 800, Loss: 4.849990, time: 4.391 sec/batch
INFO:tensorflow:Step: 804, Loss: 4.764993, time: 4.008 sec/batch
INFO:tensorflow:Step: 808, Loss: 4.823200, time: 3.830 sec/batch
INFO:tensorflow:Step: 812, Loss: 4.819564, time: 3.892 sec/batch
INFO:tensorflow:Step: 816, Loss: 5.105000, time: 3.616 sec/batch
INFO:tensorflow:Step: 820, Loss: 4.820215, time: 3.831 sec/batch
INFO:tensorflow:Step: 824, Loss: 4.814259, time: 3.190 sec/batch
INFO:tensorflow:Step: 827, Loss: 4.919144, time: 3.897 sec/batch
INFO:tensorflow:Step: 831, Loss: 4.985346, time: 3.773 sec/batch
INFO:tensorflow:Step: 835, Loss: 4.951088, time: 3.756 sec/batch
INFO:tensorflow:Step: 839, Loss: 5.005424, time: 4.724 sec/batch
INFO:tensorflow:Step: 843, Loss: 4.829291, time: 3.316 sec/batch
INFO:tensorflow:Step: 847, Loss: 4.660089, time: 4.335 sec/batch
INFO:tensorflow:Step: 851, Loss: 5.364172, time: 4.687 sec/batch
INFO:tensorflow:Step: 855, Loss: 4.732852, time: 3.810 sec/batch
INFO:tensorflow:Step: 859, Loss: 4.803412, time: 3.759 sec/batch
INFO:tensorflow:Step: 863, Loss: 4.973535, time: 4.099 sec/batch
INFO:tensorflow:Step: 867, Loss: 4.867098, time: 3.935 sec/batch
E tensorflow/core/distributed_runtime/master_session.cc:923] Cleanup partition error: Unavailable: 
Traceback (most recent call last):
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 330, in train
    loss_value, step = sess.run([train_op, global_step])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 333, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 573, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 648, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError
run-expr-32node.sh: line 25: 39832 Terminated              CUDA_VISIBLE_DEVICES=$1 bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/home/data/sample-data-$2 --job_name='worker' --task_id=$2 --ps_hosts='master:2200' --worker_hosts='master:2201,master:2202,master:2203,master:2204,node001:2205,node001:2206,node001:2207,node001:2208,node002:2209,node002:2210,node002:2211,node002:2212,node003:2213,node003:2214,node003:2215,node003:2216' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
