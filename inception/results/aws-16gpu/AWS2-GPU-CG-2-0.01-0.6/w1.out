I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['master:2200']
INFO:tensorflow:Worker hosts are: ['master:2201', 'master:2202', 'master:2203', 'master:2204', 'node001:2205', 'node001:2206', 'node001:2207', 'node001:2208', 'node002:2209', 'node002:2210', 'node002:2211', 'node002:2212', 'node003:2213', 'node003:2214', 'node003:2215', 'node003:2216']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:784] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {master:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2201, master:2202, master:2203, master:2204, node001:2205, node001:2206, node001:2207, node001:2208, node002:2209, node002:2210, node002:2211, node002:2212, node003:2213, node003:2214, node003:2215, node003:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2201
INFO:tensorflow:Learning rate: 0.010000, momentum: 0.600000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 2
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 8
INFO:tensorflow:Tokens per step: 8
INFO:tensorflow:2016-08-09 16:32:48.475559 Supervisor
INFO:tensorflow:Restored model from /home/snapshot/model.ckpt-399
INFO:tensorflow:got sessions! 2016-08-09 16:33:41.670486 
INFO:tensorflow:Started 3 queues for processing input data.
INFO:tensorflow:global_step/sec: 0
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 325.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3869 get requests, put_count=2852 evicted_count=1000 eviction_rate=0.350631 and unsatisfied allocation rate=0.54717
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Loss: 5.255519, time: 18.177 sec/batch
INFO:tensorflow:Step: 399, Loss: 5.583407, time: 3.118 sec/batch
INFO:tensorflow:Step: 400, Loss: 5.190855, time: 3.743 sec/batch
INFO:tensorflow:Step: 401, Loss: 5.702099, time: 4.400 sec/batch
INFO:tensorflow:Step: 403, Loss: 5.692000, time: 2.982 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 404, Loss: 5.574650, time: 3.100 sec/batch
INFO:tensorflow:Step: 405, Loss: 5.622175, time: 2.626 sec/batch
INFO:tensorflow:Step: 406, Loss: 5.502868, time: 3.033 sec/batch
INFO:tensorflow:Step: 408, Loss: 5.851063, time: 4.109 sec/batch
INFO:tensorflow:Step: 410, Loss: 5.536048, time: 4.065 sec/batch
INFO:tensorflow:Step: 412, Loss: 5.574331, time: 4.080 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4058 evicted_count=2000 eviction_rate=0.492854 and unsatisfied allocation rate=0.460456
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 281 to 309
INFO:tensorflow:Step: 414, Loss: 5.835081, time: 5.276 sec/batch
INFO:tensorflow:Step: 416, Loss: 5.481280, time: 5.019 sec/batch
INFO:tensorflow:Step: 418, Loss: 5.356054, time: 4.621 sec/batch
INFO:tensorflow:Step: 420, Loss: 5.714847, time: 4.503 sec/batch
INFO:tensorflow:Step: 422, Loss: 5.589244, time: 5.594 sec/batch
INFO:tensorflow:Step: 424, Loss: 5.639470, time: 4.386 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1049 evicted_count=1000 eviction_rate=0.953289 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 426, Loss: 6.725340, time: 4.493 sec/batch
INFO:tensorflow:Step: 428, Loss: 5.066410, time: 4.731 sec/batch
INFO:tensorflow:Step: 430, Loss: 5.433860, time: 4.499 sec/batch
INFO:tensorflow:Step: 432, Loss: 5.274484, time: 4.532 sec/batch
INFO:tensorflow:Step: 434, Loss: 5.813909, time: 4.721 sec/batch
INFO:tensorflow:Step: 436, Loss: 5.690159, time: 4.107 sec/batch
INFO:tensorflow:Step: 438, Loss: 5.991658, time: 4.684 sec/batch
INFO:tensorflow:global_step/sec: 0.353034
INFO:tensorflow:Step: 440, Loss: 5.413441, time: 4.758 sec/batch
INFO:tensorflow:Step: 442, Loss: 5.435099, time: 4.390 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4017 evicted_count=1000 eviction_rate=0.248942 and unsatisfied allocation rate=0.227176
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:Step: 444, Loss: 5.713672, time: 4.445 sec/batch
INFO:tensorflow:Step: 446, Loss: 5.496382, time: 4.406 sec/batch
INFO:tensorflow:Step: 448, Loss: 5.574031, time: 4.711 sec/batch
INFO:tensorflow:Step: 450, Loss: 5.051105, time: 5.259 sec/batch
INFO:tensorflow:Step: 452, Loss: 5.432299, time: 4.856 sec/batch
INFO:tensorflow:Step: 454, Loss: 5.593804, time: 4.856 sec/batch
INFO:tensorflow:Step: 456, Loss: 5.453741, time: 5.140 sec/batch
INFO:tensorflow:Step: 458, Loss: 5.361457, time: 5.279 sec/batch
INFO:tensorflow:Step: 460, Loss: 5.161683, time: 4.825 sec/batch
INFO:tensorflow:Step: 462, Loss: 5.056880, time: 4.243 sec/batch
INFO:tensorflow:Step: 464, Loss: 5.263997, time: 6.850 sec/batch
INFO:tensorflow:Step: 466, Loss: 5.281504, time: 4.085 sec/batch
INFO:tensorflow:Step: 468, Loss: 5.389091, time: 4.826 sec/batch
INFO:tensorflow:Step: 470, Loss: 5.356881, time: 4.381 sec/batch
INFO:tensorflow:Step: 472, Loss: 5.411143, time: 4.762 sec/batch
INFO:tensorflow:Step: 474, Loss: 4.907707, time: 4.464 sec/batch
INFO:tensorflow:Step: 476, Loss: 5.813240, time: 4.426 sec/batch
INFO:tensorflow:Step: 478, Loss: 6.156660, time: 3.972 sec/batch
INFO:tensorflow:Step: 480, Loss: 4.860102, time: 4.702 sec/batch
INFO:tensorflow:Step: 482, Loss: 5.257129, time: 4.468 sec/batch
INFO:tensorflow:Step: 484, Loss: 4.890049, time: 4.772 sec/batch
INFO:tensorflow:Step: 486, Loss: 5.201647, time: 4.917 sec/batch
INFO:tensorflow:Step: 488, Loss: 6.037287, time: 4.846 sec/batch
INFO:tensorflow:Step: 490, Loss: 5.180367, time: 4.726 sec/batch
INFO:tensorflow:global_step/sec: 0.421527
INFO:tensorflow:Step: 492, Loss: 5.172596, time: 4.761 sec/batch
INFO:tensorflow:Step: 494, Loss: 5.054078, time: 4.720 sec/batch
INFO:tensorflow:Step: 496, Loss: 5.213485, time: 4.560 sec/batch
INFO:tensorflow:Step: 498, Loss: 4.939062, time: 6.503 sec/batch
INFO:tensorflow:Step: 500, Loss: 5.476896, time: 6.527 sec/batch
INFO:tensorflow:Step: 503, Loss: 5.112179, time: 5.326 sec/batch
INFO:tensorflow:Step: 505, Loss: 5.390910, time: 4.394 sec/batch
INFO:tensorflow:Step: 507, Loss: 5.046527, time: 4.304 sec/batch
INFO:tensorflow:Step: 509, Loss: 5.151843, time: 5.255 sec/batch
INFO:tensorflow:Step: 511, Loss: 5.028931, time: 4.579 sec/batch
INFO:tensorflow:Step: 513, Loss: 5.087595, time: 4.725 sec/batch
INFO:tensorflow:Step: 515, Loss: 4.771856, time: 4.564 sec/batch
INFO:tensorflow:Step: 517, Loss: 4.653937, time: 3.890 sec/batch
INFO:tensorflow:Step: 519, Loss: 4.800821, time: 4.637 sec/batch
INFO:tensorflow:Step: 521, Loss: 5.122906, time: 4.683 sec/batch
INFO:tensorflow:Step: 523, Loss: 5.319700, time: 4.739 sec/batch
INFO:tensorflow:Step: 525, Loss: 5.070882, time: 4.624 sec/batch
INFO:tensorflow:Step: 527, Loss: 5.106722, time: 4.616 sec/batch
INFO:tensorflow:Step: 529, Loss: 4.936063, time: 4.545 sec/batch
INFO:tensorflow:Step: 531, Loss: 4.935764, time: 4.249 sec/batch
INFO:tensorflow:Step: 533, Loss: 4.967086, time: 4.375 sec/batch
INFO:tensorflow:Step: 535, Loss: 5.101819, time: 4.580 sec/batch
INFO:tensorflow:Step: 537, Loss: 4.985980, time: 4.324 sec/batch
INFO:tensorflow:Step: 539, Loss: 5.151279, time: 5.620 sec/batch
INFO:tensorflow:Step: 541, Loss: 4.897666, time: 4.173 sec/batch
INFO:tensorflow:global_step/sec: 0.428545
INFO:tensorflow:Step: 543, Loss: 4.720942, time: 4.148 sec/batch
INFO:tensorflow:Step: 545, Loss: 5.053343, time: 4.499 sec/batch
INFO:tensorflow:Step: 547, Loss: 4.751358, time: 4.416 sec/batch
INFO:tensorflow:Step: 549, Loss: 5.651478, time: 4.503 sec/batch
INFO:tensorflow:Step: 551, Loss: 4.940057, time: 5.843 sec/batch
INFO:tensorflow:Step: 553, Loss: 5.754110, time: 4.353 sec/batch
INFO:tensorflow:Step: 555, Loss: 5.329929, time: 4.172 sec/batch
INFO:tensorflow:Step: 557, Loss: 4.705001, time: 4.090 sec/batch
INFO:tensorflow:Step: 559, Loss: 5.228200, time: 4.837 sec/batch
INFO:tensorflow:Step: 561, Loss: 4.732990, time: 4.308 sec/batch
INFO:tensorflow:Step: 563, Loss: 4.920403, time: 4.529 sec/batch
INFO:tensorflow:Step: 565, Loss: 5.163153, time: 5.044 sec/batch
INFO:tensorflow:Step: 567, Loss: 5.123019, time: 5.579 sec/batch
INFO:tensorflow:Step: 569, Loss: 5.198552, time: 4.912 sec/batch
INFO:tensorflow:Step: 571, Loss: 5.582216, time: 4.213 sec/batch
INFO:tensorflow:Step: 573, Loss: 5.587234, time: 3.935 sec/batch
INFO:tensorflow:Step: 575, Loss: 5.073975, time: 4.482 sec/batch
INFO:tensorflow:Step: 577, Loss: 5.169235, time: 3.834 sec/batch
INFO:tensorflow:Step: 579, Loss: 4.956119, time: 4.249 sec/batch
INFO:tensorflow:Step: 581, Loss: 5.143064, time: 4.178 sec/batch
INFO:tensorflow:Step: 583, Loss: 5.397281, time: 3.694 sec/batch
INFO:tensorflow:Step: 585, Loss: 4.581561, time: 4.196 sec/batch
INFO:tensorflow:Step: 587, Loss: 5.642896, time: 5.578 sec/batch
INFO:tensorflow:Step: 589, Loss: 4.847390, time: 4.534 sec/batch
INFO:tensorflow:Step: 591, Loss: 4.799993, time: 4.248 sec/batch
INFO:tensorflow:Step: 593, Loss: 5.067529, time: 4.455 sec/batch
INFO:tensorflow:Step: 595, Loss: 4.640564, time: 4.303 sec/batch
INFO:tensorflow:global_step/sec: 0.449903
INFO:tensorflow:Step: 597, Loss: 4.700095, time: 4.171 sec/batch
INFO:tensorflow:Step: 599, Loss: 4.649771, time: 4.505 sec/batch
INFO:tensorflow:Step: 601, Loss: 4.835847, time: 4.600 sec/batch
INFO:tensorflow:Step: 603, Loss: 4.775016, time: 4.651 sec/batch
INFO:tensorflow:Step: 605, Loss: 4.646241, time: 5.007 sec/batch
INFO:tensorflow:Step: 607, Loss: 5.380279, time: 4.742 sec/batch
INFO:tensorflow:Step: 609, Loss: 4.656894, time: 4.136 sec/batch
INFO:tensorflow:Step: 611, Loss: 4.779528, time: 4.483 sec/batch
INFO:tensorflow:Step: 613, Loss: 5.053400, time: 4.074 sec/batch
run-expr-32node.sh: line 25: 101469 Terminated              CUDA_VISIBLE_DEVICES=$1 bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/home/data/sample-data-$2 --job_name='worker' --task_id=$2 --ps_hosts='master:2200' --worker_hosts='master:2201,master:2202,master:2203,master:2204,node001:2205,node001:2206,node001:2207,node001:2208,node002:2209,node002:2210,node002:2211,node002:2212,node003:2213,node003:2214,node003:2215,node003:2216' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
