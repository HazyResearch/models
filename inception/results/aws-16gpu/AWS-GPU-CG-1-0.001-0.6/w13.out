I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['master:2200']
INFO:tensorflow:Worker hosts are: ['master:2201', 'master:2202', 'master:2203', 'master:2204', 'node001:2205', 'node001:2206', 'node001:2207', 'node001:2208', 'node002:2209', 'node002:2210', 'node002:2211', 'node002:2212', 'node003:2213', 'node003:2214', 'node003:2215', 'node003:2216']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:784] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {master:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {master:2201, master:2202, master:2203, master:2204, node001:2205, node001:2206, node001:2207, node001:2208, node002:2209, node002:2210, node002:2211, node002:2212, localhost:2213, node003:2214, node003:2215, node003:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2213
INFO:tensorflow:Learning rate: 0.001000, momentum: 0.600000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 1
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 16
INFO:tensorflow:Tokens per step: 16
INFO:tensorflow:2016-08-09 05:29:51.427660 Supervisor
INFO:tensorflow:got sessions! 2016-08-09 05:30:08.385440 
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=2855 evicted_count=1000 eviction_rate=0.350263 and unsatisfied allocation rate=0.534236
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Loss: 6.227801, time: 19.573 sec/batch
INFO:tensorflow:Step: 399, Loss: 5.838368, time: 6.853 sec/batch
INFO:tensorflow:Step: 400, Loss: 5.664264, time: 8.874 sec/batch
INFO:tensorflow:Step: 402, Loss: 5.536211, time: 5.675 sec/batch
INFO:tensorflow:Step: 403, Loss: 5.174225, time: 5.121 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 404, Loss: 5.240981, time: 5.440 sec/batch
INFO:tensorflow:Step: 405, Loss: 5.259666, time: 4.755 sec/batch
INFO:tensorflow:Step: 406, Loss: 5.528739, time: 5.633 sec/batch
INFO:tensorflow:Step: 407, Loss: 5.376917, time: 5.154 sec/batch
INFO:tensorflow:Step: 408, Loss: 5.571837, time: 6.734 sec/batch
INFO:tensorflow:Step: 409, Loss: 5.661502, time: 6.496 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4058 evicted_count=2000 eviction_rate=0.492854 and unsatisfied allocation rate=0.460456
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 281 to 309
INFO:tensorflow:Step: 410, Loss: 5.415960, time: 5.176 sec/batch
INFO:tensorflow:Step: 411, Loss: 5.489054, time: 5.162 sec/batch
INFO:tensorflow:Step: 412, Loss: 5.312109, time: 5.760 sec/batch
INFO:tensorflow:Step: 413, Loss: 5.529884, time: 4.980 sec/batch
INFO:tensorflow:Step: 414, Loss: 5.417989, time: 5.099 sec/batch
INFO:tensorflow:Step: 415, Loss: 5.226349, time: 6.238 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1049 evicted_count=1000 eviction_rate=0.953289 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 416, Loss: 5.593412, time: 5.204 sec/batch
INFO:tensorflow:Step: 417, Loss: 5.486025, time: 5.226 sec/batch
INFO:tensorflow:Step: 418, Loss: 5.546656, time: 5.358 sec/batch
INFO:tensorflow:Step: 419, Loss: 5.183151, time: 5.436 sec/batch
INFO:tensorflow:Step: 420, Loss: 5.618656, time: 5.229 sec/batch
INFO:tensorflow:Step: 421, Loss: 5.086244, time: 5.790 sec/batch
INFO:tensorflow:Step: 422, Loss: 5.525690, time: 5.315 sec/batch
INFO:tensorflow:Step: 423, Loss: 5.405550, time: 5.708 sec/batch
INFO:tensorflow:Step: 424, Loss: 5.944710, time: 5.523 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4017 evicted_count=1000 eviction_rate=0.248942 and unsatisfied allocation rate=0.227176
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:Step: 425, Loss: 5.393516, time: 5.048 sec/batch
INFO:tensorflow:Step: 426, Loss: 5.027818, time: 5.561 sec/batch
INFO:tensorflow:Step: 427, Loss: 5.299138, time: 5.353 sec/batch
INFO:tensorflow:Step: 428, Loss: 5.306614, time: 5.365 sec/batch
INFO:tensorflow:Step: 429, Loss: 5.727960, time: 5.649 sec/batch
INFO:tensorflow:Step: 430, Loss: 5.253046, time: 5.288 sec/batch
INFO:tensorflow:Step: 431, Loss: 5.288275, time: 5.584 sec/batch
INFO:tensorflow:Step: 432, Loss: 5.637131, time: 4.993 sec/batch
INFO:tensorflow:Step: 433, Loss: 5.568411, time: 5.255 sec/batch
INFO:tensorflow:Step: 434, Loss: 5.006603, time: 5.460 sec/batch
INFO:tensorflow:Step: 435, Loss: 6.011453, time: 5.680 sec/batch
INFO:tensorflow:Step: 436, Loss: 5.446618, time: 6.096 sec/batch
INFO:tensorflow:Step: 437, Loss: 5.749459, time: 5.454 sec/batch
INFO:tensorflow:Step: 438, Loss: 5.283035, time: 5.669 sec/batch
INFO:tensorflow:Step: 439, Loss: 5.638622, time: 5.195 sec/batch
INFO:tensorflow:Step: 440, Loss: 5.537756, time: 5.548 sec/batch
INFO:tensorflow:Step: 441, Loss: 5.321655, time: 5.080 sec/batch
INFO:tensorflow:Step: 442, Loss: 5.546966, time: 5.946 sec/batch
INFO:tensorflow:Step: 443, Loss: 5.522867, time: 5.062 sec/batch
INFO:tensorflow:Step: 444, Loss: 5.648589, time: 5.326 sec/batch
INFO:tensorflow:Step: 445, Loss: 4.953735, time: 5.184 sec/batch
INFO:tensorflow:Step: 446, Loss: 5.196547, time: 5.428 sec/batch
INFO:tensorflow:Step: 447, Loss: 5.177762, time: 5.168 sec/batch
INFO:tensorflow:Step: 448, Loss: 5.199283, time: 4.891 sec/batch
INFO:tensorflow:Step: 449, Loss: 5.375383, time: 5.290 sec/batch
INFO:tensorflow:Step: 450, Loss: 5.477146, time: 4.981 sec/batch
INFO:tensorflow:Step: 451, Loss: 5.593833, time: 4.974 sec/batch
INFO:tensorflow:Step: 452, Loss: 5.265647, time: 4.872 sec/batch
INFO:tensorflow:Step: 453, Loss: 5.318326, time: 5.318 sec/batch
INFO:tensorflow:Step: 454, Loss: 5.342859, time: 5.230 sec/batch
INFO:tensorflow:Step: 455, Loss: 5.192269, time: 5.323 sec/batch
INFO:tensorflow:Step: 456, Loss: 5.276667, time: 5.917 sec/batch
INFO:tensorflow:Step: 457, Loss: 5.379373, time: 5.439 sec/batch
INFO:tensorflow:Step: 458, Loss: 5.138919, time: 5.903 sec/batch
INFO:tensorflow:Step: 459, Loss: 5.480236, time: 4.801 sec/batch
INFO:tensorflow:Step: 460, Loss: 5.387197, time: 4.897 sec/batch
INFO:tensorflow:Step: 461, Loss: 5.318763, time: 4.859 sec/batch
INFO:tensorflow:Step: 462, Loss: 5.304259, time: 6.092 sec/batch
INFO:tensorflow:Step: 463, Loss: 5.119750, time: 6.029 sec/batch
INFO:tensorflow:Step: 464, Loss: 5.236282, time: 5.877 sec/batch
INFO:tensorflow:Step: 465, Loss: 5.366515, time: 5.394 sec/batch
INFO:tensorflow:Step: 466, Loss: 5.720362, time: 5.966 sec/batch
INFO:tensorflow:Step: 467, Loss: 4.970175, time: 5.993 sec/batch
INFO:tensorflow:Step: 468, Loss: 5.378253, time: 5.557 sec/batch
INFO:tensorflow:Step: 469, Loss: 5.563630, time: 6.311 sec/batch
INFO:tensorflow:Step: 470, Loss: 5.188397, time: 5.785 sec/batch
INFO:tensorflow:Step: 471, Loss: 5.116576, time: 5.495 sec/batch
INFO:tensorflow:Step: 472, Loss: 5.557090, time: 5.277 sec/batch
INFO:tensorflow:Step: 473, Loss: 5.642925, time: 5.143 sec/batch
INFO:tensorflow:Step: 474, Loss: 5.199548, time: 5.041 sec/batch
INFO:tensorflow:Step: 475, Loss: 5.160917, time: 5.635 sec/batch
INFO:tensorflow:Step: 476, Loss: 5.221883, time: 5.348 sec/batch
INFO:tensorflow:Step: 477, Loss: 5.374844, time: 4.924 sec/batch
INFO:tensorflow:Step: 478, Loss: 5.092508, time: 4.864 sec/batch
INFO:tensorflow:Step: 479, Loss: 5.287058, time: 5.410 sec/batch
INFO:tensorflow:Step: 480, Loss: 5.134251, time: 6.249 sec/batch
INFO:tensorflow:Step: 481, Loss: 5.579859, time: 5.118 sec/batch
INFO:tensorflow:Step: 482, Loss: 5.378350, time: 4.688 sec/batch
INFO:tensorflow:Step: 483, Loss: 5.348033, time: 4.945 sec/batch
INFO:tensorflow:Step: 484, Loss: 5.297379, time: 4.932 sec/batch
INFO:tensorflow:Step: 485, Loss: 5.178869, time: 5.031 sec/batch
INFO:tensorflow:Step: 486, Loss: 5.586956, time: 5.062 sec/batch
INFO:tensorflow:Step: 487, Loss: 5.368176, time: 4.972 sec/batch
INFO:tensorflow:Step: 488, Loss: 5.272972, time: 4.727 sec/batch
INFO:tensorflow:Step: 489, Loss: 5.168330, time: 5.582 sec/batch
INFO:tensorflow:Step: 490, Loss: 5.196403, time: 6.249 sec/batch
Traceback (most recent call last):
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 330, in train
    loss_value, step = sess.run([train_op, global_step])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 333, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 573, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 648, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError
run-expr-32node.sh: line 25: 125576 Terminated              CUDA_VISIBLE_DEVICES=$1 bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/home/data/sample-data-$2 --job_name='worker' --task_id=$2 --ps_hosts='master:2200' --worker_hosts='master:2201,master:2202,master:2203,master:2204,node001:2205,node001:2206,node001:2207,node001:2208,node002:2209,node002:2210,node002:2211,node002:2212,node003:2213,node003:2214,node003:2215,node003:2216' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
