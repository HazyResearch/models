I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['master:2200']
INFO:tensorflow:Worker hosts are: ['master:2201', 'master:2202', 'master:2203', 'master:2204', 'node001:2205', 'node001:2206', 'node001:2207', 'node001:2208', 'node002:2209', 'node002:2210', 'node002:2211', 'node002:2212', 'node003:2213', 'node003:2214', 'node003:2215', 'node003:2216']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:04.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:784] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:04.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {master:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {master:2201, master:2202, master:2203, master:2204, node001:2205, node001:2206, node001:2207, node001:2208, node002:2209, node002:2210, node002:2211, node002:2212, node003:2213, localhost:2214, node003:2215, node003:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2214
INFO:tensorflow:Learning rate: 0.001000, momentum: 0.600000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 1
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 16
INFO:tensorflow:Tokens per step: 16
INFO:tensorflow:2016-08-09 05:29:52.555599 Supervisor
INFO:tensorflow:got sessions! 2016-08-09 05:30:09.787302 
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=2855 evicted_count=1000 eviction_rate=0.350263 and unsatisfied allocation rate=0.534236
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Loss: 5.146780, time: 20.211 sec/batch
INFO:tensorflow:Step: 399, Loss: 5.969110, time: 6.213 sec/batch
INFO:tensorflow:Step: 400, Loss: 5.375052, time: 7.710 sec/batch
INFO:tensorflow:Step: 401, Loss: 4.903184, time: 6.849 sec/batch
INFO:tensorflow:Step: 403, Loss: 5.604479, time: 5.186 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 404, Loss: 5.101102, time: 5.359 sec/batch
INFO:tensorflow:Step: 405, Loss: 5.204933, time: 4.767 sec/batch
INFO:tensorflow:Step: 406, Loss: 5.043503, time: 5.621 sec/batch
INFO:tensorflow:Step: 407, Loss: 5.025490, time: 5.165 sec/batch
INFO:tensorflow:Step: 408, Loss: 6.179554, time: 6.736 sec/batch
INFO:tensorflow:Step: 409, Loss: 5.037440, time: 6.459 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4058 evicted_count=2000 eviction_rate=0.492854 and unsatisfied allocation rate=0.460456
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 281 to 309
INFO:tensorflow:Step: 410, Loss: 5.099927, time: 5.247 sec/batch
INFO:tensorflow:Step: 411, Loss: 4.930272, time: 5.116 sec/batch
INFO:tensorflow:Step: 412, Loss: 5.270756, time: 5.787 sec/batch
INFO:tensorflow:Step: 413, Loss: 5.103488, time: 4.921 sec/batch
INFO:tensorflow:Step: 414, Loss: 5.177022, time: 5.202 sec/batch
INFO:tensorflow:Step: 415, Loss: 5.132419, time: 6.148 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1049 evicted_count=1000 eviction_rate=0.953289 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 416, Loss: 5.249370, time: 5.249 sec/batch
INFO:tensorflow:Step: 417, Loss: 5.442322, time: 5.187 sec/batch
INFO:tensorflow:Step: 418, Loss: 5.785335, time: 5.415 sec/batch
INFO:tensorflow:Step: 419, Loss: 4.836132, time: 5.497 sec/batch
INFO:tensorflow:Step: 420, Loss: 5.524002, time: 5.139 sec/batch
INFO:tensorflow:Step: 421, Loss: 5.055749, time: 5.771 sec/batch
INFO:tensorflow:Step: 422, Loss: 5.064673, time: 5.310 sec/batch
INFO:tensorflow:Step: 423, Loss: 5.114336, time: 5.731 sec/batch
INFO:tensorflow:Step: 424, Loss: 5.290218, time: 5.502 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4015 evicted_count=1000 eviction_rate=0.249066 and unsatisfied allocation rate=0.227707
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:Step: 425, Loss: 5.441766, time: 5.055 sec/batch
INFO:tensorflow:Step: 426, Loss: 5.214724, time: 5.563 sec/batch
INFO:tensorflow:Step: 427, Loss: 5.235641, time: 5.352 sec/batch
INFO:tensorflow:Step: 428, Loss: 5.675409, time: 5.356 sec/batch
INFO:tensorflow:Step: 429, Loss: 5.005668, time: 5.687 sec/batch
INFO:tensorflow:Step: 430, Loss: 4.859059, time: 5.251 sec/batch
INFO:tensorflow:Step: 431, Loss: 4.931454, time: 5.599 sec/batch
INFO:tensorflow:Step: 432, Loss: 5.434545, time: 4.980 sec/batch
INFO:tensorflow:Step: 433, Loss: 5.177025, time: 5.301 sec/batch
INFO:tensorflow:Step: 434, Loss: 5.201511, time: 5.404 sec/batch
INFO:tensorflow:Step: 435, Loss: 5.104015, time: 5.700 sec/batch
INFO:tensorflow:Step: 436, Loss: 5.387453, time: 6.055 sec/batch
INFO:tensorflow:Step: 437, Loss: 5.442441, time: 5.532 sec/batch
INFO:tensorflow:Step: 438, Loss: 4.737503, time: 5.624 sec/batch
INFO:tensorflow:Step: 439, Loss: 5.482581, time: 5.264 sec/batch
INFO:tensorflow:Step: 440, Loss: 5.296042, time: 5.427 sec/batch
INFO:tensorflow:Step: 441, Loss: 4.996729, time: 5.129 sec/batch
INFO:tensorflow:Step: 442, Loss: 5.258873, time: 6.048 sec/batch
INFO:tensorflow:Step: 443, Loss: 5.191946, time: 4.901 sec/batch
INFO:tensorflow:Step: 444, Loss: 4.980707, time: 5.486 sec/batch
INFO:tensorflow:Step: 445, Loss: 5.274477, time: 5.074 sec/batch
INFO:tensorflow:Step: 446, Loss: 5.250948, time: 5.438 sec/batch
INFO:tensorflow:Step: 447, Loss: 5.136595, time: 5.104 sec/batch
INFO:tensorflow:Step: 448, Loss: 5.447900, time: 4.959 sec/batch
INFO:tensorflow:Step: 449, Loss: 5.094688, time: 5.309 sec/batch
INFO:tensorflow:Step: 450, Loss: 5.177885, time: 4.959 sec/batch
INFO:tensorflow:Step: 451, Loss: 5.132369, time: 4.948 sec/batch
INFO:tensorflow:Step: 452, Loss: 4.874745, time: 4.900 sec/batch
INFO:tensorflow:Step: 453, Loss: 5.121235, time: 5.195 sec/batch
INFO:tensorflow:Step: 454, Loss: 5.203673, time: 5.334 sec/batch
INFO:tensorflow:Step: 455, Loss: 5.527588, time: 5.346 sec/batch
INFO:tensorflow:Step: 456, Loss: 5.061963, time: 5.907 sec/batch
INFO:tensorflow:Step: 457, Loss: 4.874268, time: 5.451 sec/batch
INFO:tensorflow:Step: 458, Loss: 5.289507, time: 5.832 sec/batch
INFO:tensorflow:Step: 459, Loss: 5.115542, time: 4.882 sec/batch
INFO:tensorflow:Step: 460, Loss: 5.156034, time: 4.881 sec/batch
INFO:tensorflow:Step: 461, Loss: 5.259042, time: 4.980 sec/batch
INFO:tensorflow:Step: 462, Loss: 5.036279, time: 5.958 sec/batch
INFO:tensorflow:Step: 463, Loss: 5.028273, time: 6.048 sec/batch
INFO:tensorflow:Step: 464, Loss: 5.044907, time: 5.872 sec/batch
INFO:tensorflow:Step: 465, Loss: 4.975937, time: 5.418 sec/batch
INFO:tensorflow:Step: 466, Loss: 5.271231, time: 5.911 sec/batch
INFO:tensorflow:Step: 467, Loss: 5.227110, time: 6.026 sec/batch
INFO:tensorflow:Step: 468, Loss: 5.139904, time: 5.522 sec/batch
INFO:tensorflow:Step: 469, Loss: 5.299352, time: 6.352 sec/batch
INFO:tensorflow:Step: 470, Loss: 5.282339, time: 5.783 sec/batch
INFO:tensorflow:Step: 471, Loss: 4.850543, time: 5.382 sec/batch
INFO:tensorflow:Step: 472, Loss: 5.005870, time: 5.383 sec/batch
INFO:tensorflow:Step: 473, Loss: 4.908970, time: 5.123 sec/batch
INFO:tensorflow:Step: 474, Loss: 5.287231, time: 5.113 sec/batch
INFO:tensorflow:Step: 475, Loss: 4.978531, time: 5.658 sec/batch
INFO:tensorflow:Step: 476, Loss: 5.276516, time: 5.265 sec/batch
INFO:tensorflow:Step: 477, Loss: 5.009959, time: 4.982 sec/batch
INFO:tensorflow:Step: 478, Loss: 5.063505, time: 4.811 sec/batch
INFO:tensorflow:Step: 479, Loss: 4.950701, time: 5.400 sec/batch
INFO:tensorflow:Step: 480, Loss: 5.141623, time: 6.206 sec/batch
INFO:tensorflow:Step: 481, Loss: 5.130458, time: 5.193 sec/batch
INFO:tensorflow:Step: 482, Loss: 5.457481, time: 4.665 sec/batch
INFO:tensorflow:Step: 483, Loss: 5.432843, time: 4.948 sec/batch
INFO:tensorflow:Step: 484, Loss: 5.054538, time: 4.938 sec/batch
INFO:tensorflow:Step: 485, Loss: 5.147269, time: 5.030 sec/batch
INFO:tensorflow:Step: 486, Loss: 5.223567, time: 5.063 sec/batch
INFO:tensorflow:Step: 487, Loss: 5.009449, time: 4.945 sec/batch
INFO:tensorflow:Step: 488, Loss: 4.985218, time: 4.750 sec/batch
INFO:tensorflow:Step: 489, Loss: 4.802609, time: 5.516 sec/batch
INFO:tensorflow:Step: 490, Loss: 5.133772, time: 6.325 sec/batch
Traceback (most recent call last):
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 330, in train
    loss_value, step = sess.run([train_op, global_step])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 333, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 573, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 648, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError
run-expr-32node.sh: line 25: 125589 Terminated              CUDA_VISIBLE_DEVICES=$1 bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/home/data/sample-data-$2 --job_name='worker' --task_id=$2 --ps_hosts='master:2200' --worker_hosts='master:2201,master:2202,master:2203,master:2204,node001:2205,node001:2206,node001:2207,node001:2208,node002:2209,node002:2210,node002:2211,node002:2212,node003:2213,node003:2214,node003:2215,node003:2216' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
