I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['master:2200']
INFO:tensorflow:Worker hosts are: ['master:2201', 'master:2202', 'master:2203', 'master:2204', 'node001:2205', 'node001:2206', 'node001:2207', 'node001:2208', 'node002:2209', 'node002:2210', 'node002:2211', 'node002:2212', 'node003:2213', 'node003:2214', 'node003:2215', 'node003:2216', 'node004:2217', 'node004:2218', 'node004:2219', 'node004:2220', 'node005:2221', 'node005:2222', 'node005:2223', 'node005:2224', 'node006:2225', 'node006:2226', 'node006:2227', 'node006:2228', 'node007:2229', 'node007:2230', 'node007:2231', 'node007:2232']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:784] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {master:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2201, master:2202, master:2203, master:2204, node001:2205, node001:2206, node001:2207, node001:2208, node002:2209, node002:2210, node002:2211, node002:2212, node003:2213, node003:2214, node003:2215, node003:2216, node004:2217, node004:2218, node004:2219, node004:2220, node005:2221, node005:2222, node005:2223, node005:2224, node006:2225, node006:2226, node006:2227, node006:2228, node007:2229, node007:2230, node007:2231, node007:2232}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2201
INFO:tensorflow:Learning rate: 0.005000, momentum: 0.900000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 1
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=32; total_num_replicas=32
INFO:tensorflow:Num nodes per compute groups: 32
INFO:tensorflow:Tokens per step: 32
INFO:tensorflow:2016-08-10 13:43:51.315973 Supervisor
INFO:tensorflow:Restored model from /imagenet/snapshot/model.ckpt-7871
INFO:tensorflow:got sessions! 2016-08-10 13:44:49.769891 
INFO:tensorflow:Started 3 queues for processing input data.
INFO:tensorflow:global_step/sec: 0
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 352.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 715.71MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 715.71MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3869 get requests, put_count=2854 evicted_count=1000 eviction_rate=0.350385 and unsatisfied allocation rate=0.546653
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 7871, Loss: 10.032443, time: 34.987 sec/batch
INFO:tensorflow:Step: 7872, Loss: 9.675743, time: 3.519 sec/batch
INFO:tensorflow:Step: 7872, Loss: 9.557525, time: 3.638 sec/batch
INFO:tensorflow:Step: 7872, Loss: 9.386647, time: 7.576 sec/batch
INFO:tensorflow:Step: 7872, Loss: 9.727567, time: 4.575 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 7873, Loss: 9.663732, time: 3.042 sec/batch
INFO:tensorflow:Step: 7873, Loss: 9.147816, time: 5.106 sec/batch
INFO:tensorflow:Step: 7873, Loss: 8.510963, time: 4.198 sec/batch
INFO:tensorflow:Step: 7874, Loss: 9.115255, time: 16.095 sec/batch
INFO:tensorflow:Step: 7875, Loss: 9.222749, time: 13.675 sec/batch
INFO:tensorflow:Step: 7876, Loss: 9.235246, time: 10.955 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4060 evicted_count=2000 eviction_rate=0.492611 and unsatisfied allocation rate=0.459926
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 281 to 309
INFO:tensorflow:global_step/sec: 0.0504172
INFO:tensorflow:Step: 7877, Loss: 9.310410, time: 15.503 sec/batch
INFO:tensorflow:Step: 7878, Loss: 9.612104, time: 13.987 sec/batch
INFO:tensorflow:Step: 7879, Loss: 9.663523, time: 13.165 sec/batch
INFO:tensorflow:Step: 7880, Loss: 9.095919, time: 13.616 sec/batch
INFO:tensorflow:Step: 7881, Loss: 9.074099, time: 13.604 sec/batch
INFO:tensorflow:Step: 7882, Loss: 9.452258, time: 10.784 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1049 evicted_count=1000 eviction_rate=0.953289 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 7883, Loss: 9.478939, time: 11.071 sec/batch
INFO:tensorflow:Step: 7884, Loss: 9.293457, time: 12.775 sec/batch
INFO:tensorflow:Step: 7885, Loss: 8.817072, time: 13.591 sec/batch
INFO:tensorflow:global_step/sec: 0.0749867
INFO:tensorflow:Step: 7886, Loss: 9.135973, time: 12.246 sec/batch
INFO:tensorflow:Step: 7887, Loss: 9.371541, time: 14.126 sec/batch
INFO:tensorflow:Step: 7888, Loss: 8.755146, time: 12.673 sec/batch
INFO:tensorflow:Step: 7889, Loss: 9.169110, time: 13.459 sec/batch
INFO:tensorflow:Step: 7890, Loss: 9.201900, time: 12.357 sec/batch
INFO:tensorflow:Step: 7891, Loss: 8.787944, time: 11.121 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4015 evicted_count=1000 eviction_rate=0.249066 and unsatisfied allocation rate=0.227707
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:Step: 7892, Loss: 8.858245, time: 13.540 sec/batch
INFO:tensorflow:Step: 7893, Loss: 8.104855, time: 12.776 sec/batch
INFO:tensorflow:Step: 7894, Loss: 9.408558, time: 12.491 sec/batch
INFO:tensorflow:Step: 7895, Loss: 9.590702, time: 13.457 sec/batch
INFO:tensorflow:global_step/sec: 0.0813074
INFO:tensorflow:Step: 7896, Loss: 8.646972, time: 13.277 sec/batch
INFO:tensorflow:Step: 7897, Loss: 9.623931, time: 11.057 sec/batch
INFO:tensorflow:Step: 7898, Loss: 8.346325, time: 12.024 sec/batch
INFO:tensorflow:Step: 7899, Loss: 8.474151, time: 12.286 sec/batch
INFO:tensorflow:Step: 7900, Loss: 9.319401, time: 14.843 sec/batch
INFO:tensorflow:Step: 7901, Loss: 9.296709, time: 12.971 sec/batch
INFO:tensorflow:Step: 7902, Loss: 9.297934, time: 11.880 sec/batch
INFO:tensorflow:Step: 7903, Loss: 10.364784, time: 11.554 sec/batch
INFO:tensorflow:Step: 7904, Loss: 9.630019, time: 13.872 sec/batch
INFO:tensorflow:global_step/sec: 0.0769219
INFO:tensorflow:Step: 7905, Loss: 9.466681, time: 12.457 sec/batch
INFO:tensorflow:Step: 7906, Loss: 9.299746, time: 14.520 sec/batch
INFO:tensorflow:Step: 7907, Loss: 8.446012, time: 11.966 sec/batch
INFO:tensorflow:Step: 7908, Loss: 9.633684, time: 11.330 sec/batch
INFO:tensorflow:Step: 7909, Loss: 8.118475, time: 11.888 sec/batch
INFO:tensorflow:Step: 7910, Loss: 9.471619, time: 12.655 sec/batch
INFO:tensorflow:Step: 7911, Loss: 8.938360, time: 13.189 sec/batch
INFO:tensorflow:Step: 7912, Loss: 9.865904, time: 12.107 sec/batch
INFO:tensorflow:Step: 7913, Loss: 8.799414, time: 13.288 sec/batch
INFO:tensorflow:Step: 7914, Loss: 9.001431, time: 10.740 sec/batch
INFO:tensorflow:global_step/sec: 0.0826574
INFO:tensorflow:Step: 7915, Loss: 8.882337, time: 13.395 sec/batch
INFO:tensorflow:Step: 7916, Loss: 8.528214, time: 11.914 sec/batch
INFO:tensorflow:Step: 7917, Loss: 8.707585, time: 11.946 sec/batch
INFO:tensorflow:Step: 7918, Loss: 8.807351, time: 11.081 sec/batch
INFO:tensorflow:Step: 7919, Loss: 9.545840, time: 12.465 sec/batch
INFO:tensorflow:Step: 7920, Loss: 10.051985, time: 15.163 sec/batch
INFO:tensorflow:Step: 7921, Loss: 8.117709, time: 11.792 sec/batch
INFO:tensorflow:Step: 7922, Loss: 8.672955, time: 13.801 sec/batch
INFO:tensorflow:Step: 7923, Loss: 8.316956, time: 12.442 sec/batch
INFO:tensorflow:global_step/sec: 0.0755929
INFO:tensorflow:Step: 7924, Loss: 9.262325, time: 15.394 sec/batch
INFO:tensorflow:Step: 7925, Loss: 9.138797, time: 11.263 sec/batch
INFO:tensorflow:Step: 7926, Loss: 9.814131, time: 11.517 sec/batch
INFO:tensorflow:Step: 7927, Loss: 8.398562, time: 12.150 sec/batch
INFO:tensorflow:Step: 7928, Loss: 9.193363, time: 14.377 sec/batch
INFO:tensorflow:Step: 7929, Loss: 9.861986, time: 12.180 sec/batch
INFO:tensorflow:Step: 7930, Loss: 9.635796, time: 12.204 sec/batch
INFO:tensorflow:Step: 7931, Loss: 9.621551, time: 10.477 sec/batch
INFO:tensorflow:Step: 7932, Loss: 9.055448, time: 11.870 sec/batch
INFO:tensorflow:Step: 7933, Loss: 8.850553, time: 13.233 sec/batch
INFO:tensorflow:global_step/sec: 0.0833685
INFO:tensorflow:Step: 7934, Loss: 9.503046, time: 12.170 sec/batch
INFO:tensorflow:Step: 7935, Loss: 8.984896, time: 13.146 sec/batch
INFO:tensorflow:Step: 7936, Loss: 9.213895, time: 13.268 sec/batch
INFO:tensorflow:Step: 7937, Loss: 10.321028, time: 13.532 sec/batch
INFO:tensorflow:Step: 7938, Loss: 8.592546, time: 11.626 sec/batch
INFO:tensorflow:Step: 7939, Loss: 8.714778, time: 10.226 sec/batch
INFO:tensorflow:Step: 7940, Loss: 9.395356, time: 11.001 sec/batch
INFO:tensorflow:Step: 7941, Loss: 9.293454, time: 11.617 sec/batch
INFO:tensorflow:Step: 7942, Loss: 8.461480, time: 12.710 sec/batch
INFO:tensorflow:Step: 7943, Loss: 9.067567, time: 13.036 sec/batch
INFO:tensorflow:global_step/sec: 0.0819202
INFO:tensorflow:Step: 7944, Loss: 9.366377, time: 11.249 sec/batch
INFO:tensorflow:Step: 7945, Loss: 9.861691, time: 10.801 sec/batch
INFO:tensorflow:Step: 7946, Loss: 9.982590, time: 15.007 sec/batch
INFO:tensorflow:Step: 7947, Loss: 9.007351, time: 13.690 sec/batch
INFO:tensorflow:Step: 7948, Loss: 8.672830, time: 12.928 sec/batch
INFO:tensorflow:Step: 7949, Loss: 8.832671, time: 12.932 sec/batch
INFO:tensorflow:Step: 7950, Loss: 8.780312, time: 10.248 sec/batch
INFO:tensorflow:Step: 7951, Loss: 8.850050, time: 11.019 sec/batch
INFO:tensorflow:Step: 7952, Loss: 8.953554, time: 15.965 sec/batch
INFO:tensorflow:global_step/sec: 0.07631
INFO:tensorflow:Step: 7953, Loss: 9.219984, time: 12.714 sec/batch
INFO:tensorflow:Step: 7954, Loss: 8.955210, time: 13.124 sec/batch
INFO:tensorflow:Step: 7955, Loss: 8.603207, time: 13.968 sec/batch
run-expr-aws-32node.sh: line 25: 87818 Terminated              CUDA_VISIBLE_DEVICES=$1 bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/imagenet/ilsvrc12_train_tfrecord_32_PARTITION/32P_p$2 --job_name='worker' --task_id=$2 --ps_hosts='master:2200' --worker_hosts='master:2201,master:2202,master:2203,master:2204,node001:2205,node001:2206,node001:2207,node001:2208,node002:2209,node002:2210,node002:2211,node002:2212,node003:2213,node003:2214,node003:2215,node003:2216,node004:2217,node004:2218,node004:2219,node004:2220,node005:2221,node005:2222,node005:2223,node005:2224,node006:2225,node006:2226,node006:2227,node006:2228,node007:2229,node007:2230,node007:2231,node007:2232' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
