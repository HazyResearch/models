I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['master:2200']
INFO:tensorflow:Worker hosts are: ['master:2201', 'master:2202', 'master:2203', 'master:2204', 'node001:2205', 'node001:2206', 'node001:2207', 'node001:2208', 'node002:2209', 'node002:2210', 'node002:2211', 'node002:2212', 'node003:2213', 'node003:2214', 'node003:2215', 'node003:2216', 'node004:2217', 'node004:2218', 'node004:2219', 'node004:2220', 'node005:2221', 'node005:2222', 'node005:2223', 'node005:2224', 'node006:2225', 'node006:2226', 'node006:2227', 'node006:2228', 'node007:2229', 'node007:2230', 'node007:2231', 'node007:2232']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:06.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:784] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:06.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {master:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {master:2201, master:2202, master:2203, master:2204, node001:2205, node001:2206, node001:2207, node001:2208, node002:2209, node002:2210, node002:2211, localhost:2212, node003:2213, node003:2214, node003:2215, node003:2216, node004:2217, node004:2218, node004:2219, node004:2220, node005:2221, node005:2222, node005:2223, node005:2224, node006:2225, node006:2226, node006:2227, node006:2228, node007:2229, node007:2230, node007:2231, node007:2232}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2212
INFO:tensorflow:Learning rate: 0.050000, momentum: 0.000000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 1
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=32; total_num_replicas=32
INFO:tensorflow:Num nodes per compute groups: 32
INFO:tensorflow:Tokens per step: 32
INFO:tensorflow:2016-08-10 09:03:04.393442 Supervisor
INFO:tensorflow:got sessions! 2016-08-10 09:03:22.791485 
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=2855 evicted_count=1000 eviction_rate=0.350263 and unsatisfied allocation rate=0.534236
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 7871, Loss: 9.006763, time: 26.313 sec/batch
INFO:tensorflow:Step: 7871, Loss: 9.826070, time: 12.118 sec/batch
INFO:tensorflow:Step: 7872, Loss: 9.694484, time: 21.038 sec/batch
INFO:tensorflow:Step: 7873, Loss: 9.581020, time: 18.243 sec/batch
INFO:tensorflow:Step: 7874, Loss: 9.883749, time: 8.290 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 7875, Loss: 10.552881, time: 11.791 sec/batch
INFO:tensorflow:Step: 7876, Loss: 9.117131, time: 13.447 sec/batch
INFO:tensorflow:Step: 7877, Loss: 9.699481, time: 11.570 sec/batch
INFO:tensorflow:Step: 7878, Loss: 9.138768, time: 13.350 sec/batch
INFO:tensorflow:Step: 7879, Loss: 10.749698, time: 12.875 sec/batch
INFO:tensorflow:Step: 7880, Loss: 9.656038, time: 12.750 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4057 evicted_count=2000 eviction_rate=0.492975 and unsatisfied allocation rate=0.460722
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 281 to 309
INFO:tensorflow:Step: 7881, Loss: 9.819362, time: 14.014 sec/batch
INFO:tensorflow:Step: 7882, Loss: 9.240904, time: 12.658 sec/batch
INFO:tensorflow:Step: 7883, Loss: 9.590238, time: 13.250 sec/batch
INFO:tensorflow:Step: 7884, Loss: 9.566475, time: 13.413 sec/batch
INFO:tensorflow:Step: 7885, Loss: 9.936303, time: 11.871 sec/batch
INFO:tensorflow:Step: 7886, Loss: 9.063544, time: 12.420 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1049 evicted_count=1000 eviction_rate=0.953289 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 7887, Loss: 9.101650, time: 13.171 sec/batch
INFO:tensorflow:Step: 7888, Loss: 8.806544, time: 11.722 sec/batch
INFO:tensorflow:Step: 7889, Loss: 8.732758, time: 14.940 sec/batch
INFO:tensorflow:Step: 7890, Loss: 8.656536, time: 12.619 sec/batch
INFO:tensorflow:Step: 7891, Loss: 8.729970, time: 13.405 sec/batch
INFO:tensorflow:Step: 7892, Loss: 9.350859, time: 13.141 sec/batch
INFO:tensorflow:Step: 7893, Loss: 9.213236, time: 11.553 sec/batch
INFO:tensorflow:Step: 7894, Loss: 9.751183, time: 11.351 sec/batch
INFO:tensorflow:Step: 7895, Loss: 9.516361, time: 14.234 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3768 get requests, put_count=4015 evicted_count=1000 eviction_rate=0.249066 and unsatisfied allocation rate=0.227707
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:Step: 7896, Loss: 10.004487, time: 14.500 sec/batch
INFO:tensorflow:Step: 7897, Loss: 8.455620, time: 11.814 sec/batch
INFO:tensorflow:Step: 7898, Loss: 9.289813, time: 12.415 sec/batch
INFO:tensorflow:Step: 7899, Loss: 9.600856, time: 13.945 sec/batch
INFO:tensorflow:Step: 7900, Loss: 9.766813, time: 12.735 sec/batch
INFO:tensorflow:Step: 7901, Loss: 9.902692, time: 12.980 sec/batch
INFO:tensorflow:Step: 7902, Loss: 9.079310, time: 14.158 sec/batch
INFO:tensorflow:Step: 7903, Loss: 8.800098, time: 12.735 sec/batch
INFO:tensorflow:Step: 7904, Loss: 8.951944, time: 12.624 sec/batch
INFO:tensorflow:Step: 7905, Loss: 9.562586, time: 12.622 sec/batch
INFO:tensorflow:Step: 7906, Loss: 9.408160, time: 13.175 sec/batch
INFO:tensorflow:Step: 7907, Loss: 8.540866, time: 13.304 sec/batch
INFO:tensorflow:Step: 7908, Loss: 9.687204, time: 14.098 sec/batch
INFO:tensorflow:Step: 7909, Loss: 9.503489, time: 13.446 sec/batch
INFO:tensorflow:Step: 7910, Loss: 9.277230, time: 13.069 sec/batch
INFO:tensorflow:Step: 7911, Loss: 9.311427, time: 11.473 sec/batch
INFO:tensorflow:Step: 7912, Loss: 8.980330, time: 13.224 sec/batch
INFO:tensorflow:Step: 7913, Loss: 9.505213, time: 12.397 sec/batch
INFO:tensorflow:Step: 7914, Loss: 9.413126, time: 12.647 sec/batch
INFO:tensorflow:Step: 7915, Loss: 9.926062, time: 12.731 sec/batch
INFO:tensorflow:Step: 7916, Loss: 9.480399, time: 11.380 sec/batch
INFO:tensorflow:Step: 7917, Loss: 8.616627, time: 12.336 sec/batch
INFO:tensorflow:Step: 7918, Loss: 9.475063, time: 13.226 sec/batch
INFO:tensorflow:Step: 7919, Loss: 8.953495, time: 12.021 sec/batch
INFO:tensorflow:Step: 7920, Loss: 8.945791, time: 12.920 sec/batch
INFO:tensorflow:Step: 7921, Loss: 10.473515, time: 13.059 sec/batch
INFO:tensorflow:Step: 7922, Loss: 8.828784, time: 13.009 sec/batch
INFO:tensorflow:Step: 7923, Loss: 9.938497, time: 12.909 sec/batch
INFO:tensorflow:Step: 7924, Loss: 9.181797, time: 12.897 sec/batch
INFO:tensorflow:Step: 7925, Loss: 9.492849, time: 12.515 sec/batch
INFO:tensorflow:Step: 7926, Loss: 8.714202, time: 14.199 sec/batch
INFO:tensorflow:Step: 7927, Loss: 9.001664, time: 12.082 sec/batch
INFO:tensorflow:Step: 7928, Loss: 9.154514, time: 13.799 sec/batch
INFO:tensorflow:Step: 7929, Loss: 9.680936, time: 12.178 sec/batch
INFO:tensorflow:Step: 7930, Loss: 9.582458, time: 12.922 sec/batch
INFO:tensorflow:Step: 7931, Loss: 9.112839, time: 13.009 sec/batch
INFO:tensorflow:Step: 7932, Loss: 8.588902, time: 12.766 sec/batch
INFO:tensorflow:Step: 7933, Loss: 9.560839, time: 12.528 sec/batch
INFO:tensorflow:Step: 7934, Loss: 9.462664, time: 14.710 sec/batch
INFO:tensorflow:Step: 7935, Loss: 8.962502, time: 11.603 sec/batch
INFO:tensorflow:Step: 7936, Loss: 9.546913, time: 13.826 sec/batch
INFO:tensorflow:Step: 7937, Loss: 8.569513, time: 11.854 sec/batch
INFO:tensorflow:Step: 7938, Loss: 9.559848, time: 12.135 sec/batch
INFO:tensorflow:Step: 7939, Loss: 9.342021, time: 13.416 sec/batch
INFO:tensorflow:Step: 7940, Loss: 9.348081, time: 11.154 sec/batch
INFO:tensorflow:Step: 7941, Loss: 8.814013, time: 12.698 sec/batch
INFO:tensorflow:Step: 7942, Loss: 9.093841, time: 13.701 sec/batch
INFO:tensorflow:Step: 7943, Loss: 9.290428, time: 15.390 sec/batch
INFO:tensorflow:Step: 7944, Loss: 8.790234, time: 13.609 sec/batch
INFO:tensorflow:Step: 7945, Loss: 9.171533, time: 13.699 sec/batch
INFO:tensorflow:Step: 7946, Loss: 8.758606, time: 15.376 sec/batch
INFO:tensorflow:Step: 7947, Loss: 8.958240, time: 13.798 sec/batch
INFO:tensorflow:Step: 7948, Loss: 8.984774, time: 13.877 sec/batch
INFO:tensorflow:Step: 7949, Loss: 9.066868, time: 13.727 sec/batch
INFO:tensorflow:Step: 7950, Loss: 9.439364, time: 13.498 sec/batch
INFO:tensorflow:Step: 7951, Loss: 8.878160, time: 13.480 sec/batch
INFO:tensorflow:Step: 7952, Loss: 9.121222, time: 12.930 sec/batch
INFO:tensorflow:Step: 7953, Loss: 9.436021, time: 14.344 sec/batch
E tensorflow/core/distributed_runtime/master_session.cc:923] Cleanup partition error: Unavailable: 
Traceback (most recent call last):
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 330, in train
    loss_value, step = sess.run([train_op, global_step])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 333, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 573, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 648, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError
run-expr-aws-32node.sh: line 25: 30229 Terminated              CUDA_VISIBLE_DEVICES=$1 bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/imagenet/ilsvrc12_train_tfrecord_32_PARTITION/32P_p$2 --job_name='worker' --task_id=$2 --ps_hosts='master:2200' --worker_hosts='master:2201,master:2202,master:2203,master:2204,node001:2205,node001:2206,node001:2207,node001:2208,node002:2209,node002:2210,node002:2211,node002:2212,node003:2213,node003:2214,node003:2215,node003:2216,node004:2217,node004:2218,node004:2219,node004:2220,node005:2221,node005:2222,node005:2223,node005:2224,node006:2225,node006:2226,node006:2227,node006:2228,node007:2229,node007:2230,node007:2231,node007:2232' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
