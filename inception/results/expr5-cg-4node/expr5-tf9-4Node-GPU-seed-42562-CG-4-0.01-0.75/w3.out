DISPLAY "(null)" invalid; disabling X11 forwarding
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['raiders1:2228']
INFO:tensorflow:Worker hosts are: ['raiders1:2200', 'raiders1:2201', 'raiders3:2209', 'raiders3:2210']
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:03:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {raiders1:2228}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {raiders1:2200, raiders1:2201, localhost:2209, raiders3:2210}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2209
INFO:tensorflow:Learning rate: 0.010000, momentum: 0.750000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 4
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=4; total_num_replicas=4
INFO:tensorflow:Num nodes per compute groups: 1
INFO:tensorflow:Tokens per step: 1
INFO:tensorflow:2016-07-19 13:47:57.711471 Supervisor
INFO:tensorflow:got sessions!
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3576 get requests, put_count=2565 evicted_count=1000 eviction_rate=0.389864 and unsatisfied allocation rate=0.590324
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Accuracy: 0.437500, Loss: 5.452036, time: 6.292 sec/batch
INFO:tensorflow:Step: 402, Accuracy: 0.578125, Loss: 5.494689, time: 1.440 sec/batch
INFO:tensorflow:Step: 405, Accuracy: 0.500000, Loss: 5.381883, time: 1.650 sec/batch
INFO:tensorflow:Step: 408, Accuracy: 0.640625, Loss: 5.783854, time: 1.580 sec/batch
INFO:tensorflow:Step: 411, Accuracy: 0.546875, Loss: 5.317073, time: 1.446 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 414, Accuracy: 0.562500, Loss: 5.502073, time: 1.775 sec/batch
INFO:tensorflow:Step: 417, Accuracy: 0.640625, Loss: 5.302479, time: 2.073 sec/batch
INFO:tensorflow:Step: 420, Accuracy: 0.593750, Loss: 5.259843, time: 1.857 sec/batch
INFO:tensorflow:Step: 423, Accuracy: 0.593750, Loss: 5.395030, time: 1.905 sec/batch
INFO:tensorflow:Step: 427, Accuracy: 0.484375, Loss: 5.525947, time: 2.198 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1025 evicted_count=1000 eviction_rate=0.97561 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 430, Accuracy: 0.734375, Loss: 5.198071, time: 1.803 sec/batch
INFO:tensorflow:Step: 433, Accuracy: 0.500000, Loss: 5.360773, time: 1.627 sec/batch
INFO:tensorflow:Step: 436, Accuracy: 0.546875, Loss: 5.377106, time: 2.194 sec/batch
INFO:tensorflow:Step: 439, Accuracy: 0.609375, Loss: 5.188446, time: 2.071 sec/batch
INFO:tensorflow:Step: 442, Accuracy: 0.578125, Loss: 5.269117, time: 2.069 sec/batch
INFO:tensorflow:Step: 445, Accuracy: 0.546875, Loss: 5.108141, time: 2.019 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1044 evicted_count=1000 eviction_rate=0.957854 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 448, Accuracy: 0.593750, Loss: 5.166319, time: 1.611 sec/batch
INFO:tensorflow:Step: 452, Accuracy: 0.625000, Loss: 5.173842, time: 1.377 sec/batch
INFO:tensorflow:Step: 455, Accuracy: 0.546875, Loss: 4.944568, time: 1.686 sec/batch
INFO:tensorflow:Step: 458, Accuracy: 0.531250, Loss: 5.229732, time: 1.342 sec/batch
INFO:tensorflow:Step: 461, Accuracy: 0.500000, Loss: 5.113939, time: 1.640 sec/batch
INFO:tensorflow:Step: 464, Accuracy: 0.484375, Loss: 4.933049, time: 1.532 sec/batch
INFO:tensorflow:Step: 467, Accuracy: 0.656250, Loss: 5.124336, time: 1.656 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3579 get requests, put_count=4417 evicted_count=2000 eviction_rate=0.452796 and unsatisfied allocation rate=0.346745
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 871 to 958
INFO:tensorflow:Step: 470, Accuracy: 0.562500, Loss: 5.174701, time: 1.321 sec/batch
INFO:tensorflow:Step: 473, Accuracy: 0.656250, Loss: 5.045562, time: 1.610 sec/batch
INFO:tensorflow:Step: 476, Accuracy: 0.625000, Loss: 5.237728, time: 1.475 sec/batch
INFO:tensorflow:Step: 479, Accuracy: 0.546875, Loss: 5.173470, time: 1.277 sec/batch
INFO:tensorflow:Step: 482, Accuracy: 0.578125, Loss: 5.211504, time: 1.244 sec/batch
INFO:tensorflow:Step: 485, Accuracy: 0.640625, Loss: 5.184813, time: 1.573 sec/batch
INFO:tensorflow:Step: 488, Accuracy: 0.578125, Loss: 5.261086, time: 1.249 sec/batch
INFO:tensorflow:Step: 492, Accuracy: 0.578125, Loss: 5.182362, time: 1.321 sec/batch
INFO:tensorflow:Step: 495, Accuracy: 0.593750, Loss: 5.210452, time: 1.282 sec/batch
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.UnavailableError'>, 
E0719 13:49:46.788426986   90569 tcp_client_posix.c:173]     failed to connect to 'ipv4:172.24.75.13:2228': socket error: connection refused
not cropping. Imagesize: 256
not cropping. Imagesize: 256
not cropping. Imagesize: 256
not cropping. Imagesize: 256
Traceback (most recent call last):
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 321, in train
    tf.logging.info("Step: %d, Accuracy: %f, Loss: %f, time: %.3f sec/batch" %(step, sess.run(accuracy), loss_value, duration))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 372, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 636, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 708, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError: 
	 [[Node: mixed_17x17x768c/branch7x7/Conv_2/weights/read_S4737 = _Recv[client_terminated=false, recv_device="/job:worker/replica:0/task:2/gpu:0", send_device="/job:ps/replica:0/task:0/cpu:0", send_device_incarnation=6764212793799932264, tensor_name="edge_2171_mixed_17x17x768c/branch7x7/Conv_2/weights/read", tensor_type=DT_FLOAT, _device="/job:worker/replica:0/task:2/gpu:0"]()]]
	 [[Node: Mean_G2445 = _Recv[client_terminated=false, recv_device="/job:worker/replica:0/task:2/cpu:0", send_device="/job:worker/replica:0/task:2/gpu:0", send_device_incarnation=4367623584705908479, tensor_name="edge_2655_Mean", tensor_type=DT_FLOAT, _device="/job:worker/replica:0/task:2/cpu:0"]()]]
