I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['raiders1:2228']
INFO:tensorflow:Worker hosts are: ['raiders1:2200', 'raiders1:2201', 'raiders3:2209', 'raiders3:2210']
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:43:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:43:00.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {raiders1:2228}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {raiders1:2200, localhost:2201, raiders3:2209, raiders3:2210}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2201
INFO:tensorflow:Learning rate: 0.010000, momentum: 0.750000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 4
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=4; total_num_replicas=4
INFO:tensorflow:Num nodes per compute groups: 1
INFO:tensorflow:Tokens per step: 1
INFO:tensorflow:2016-07-19 13:47:56.914536 Supervisor
INFO:tensorflow:got sessions!
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3576 get requests, put_count=2563 evicted_count=1000 eviction_rate=0.390168 and unsatisfied allocation rate=0.590884
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Accuracy: 0.593750, Loss: 5.227660, time: 8.020 sec/batch
INFO:tensorflow:Step: 402, Accuracy: 0.609375, Loss: 5.680455, time: 1.478 sec/batch
INFO:tensorflow:Step: 403, Accuracy: 0.546875, Loss: 5.080608, time: 1.708 sec/batch
INFO:tensorflow:Step: 406, Accuracy: 0.546875, Loss: 5.601321, time: 1.694 sec/batch
INFO:tensorflow:Step: 409, Accuracy: 0.593750, Loss: 5.274288, time: 1.567 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 412, Accuracy: 0.718750, Loss: 5.253782, time: 1.400 sec/batch
INFO:tensorflow:Step: 414, Accuracy: 0.515625, Loss: 5.312230, time: 1.255 sec/batch
INFO:tensorflow:Step: 417, Accuracy: 0.593750, Loss: 5.797120, time: 1.450 sec/batch
INFO:tensorflow:Step: 420, Accuracy: 0.500000, Loss: 5.142289, time: 1.737 sec/batch
INFO:tensorflow:Step: 422, Accuracy: 0.546875, Loss: 5.464740, time: 1.354 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1025 evicted_count=1000 eviction_rate=0.97561 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 424, Accuracy: 0.625000, Loss: 5.264966, time: 1.271 sec/batch
INFO:tensorflow:Step: 427, Accuracy: 0.671875, Loss: 5.172112, time: 1.227 sec/batch
INFO:tensorflow:Step: 430, Accuracy: 0.562500, Loss: 5.355942, time: 1.400 sec/batch
INFO:tensorflow:Step: 433, Accuracy: 0.640625, Loss: 5.358036, time: 1.461 sec/batch
INFO:tensorflow:Step: 436, Accuracy: 0.562500, Loss: 5.065619, time: 1.816 sec/batch
INFO:tensorflow:Step: 438, Accuracy: 0.593750, Loss: 5.076635, time: 1.728 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1044 evicted_count=1000 eviction_rate=0.957854 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 441, Accuracy: 0.578125, Loss: 5.220769, time: 1.474 sec/batch
INFO:tensorflow:Step: 444, Accuracy: 0.656250, Loss: 5.258748, time: 1.522 sec/batch
INFO:tensorflow:Step: 447, Accuracy: 0.671875, Loss: 5.241369, time: 1.342 sec/batch
INFO:tensorflow:Step: 450, Accuracy: 0.578125, Loss: 5.440519, time: 1.256 sec/batch
INFO:tensorflow:Step: 452, Accuracy: 0.578125, Loss: 5.403037, time: 1.233 sec/batch
INFO:tensorflow:Step: 455, Accuracy: 0.609375, Loss: 5.199416, time: 1.589 sec/batch
INFO:tensorflow:Step: 458, Accuracy: 0.640625, Loss: 5.293345, time: 1.305 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3579 get requests, put_count=4416 evicted_count=2000 eviction_rate=0.452899 and unsatisfied allocation rate=0.347024
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 871 to 958
INFO:tensorflow:Step: 461, Accuracy: 0.671875, Loss: 5.191625, time: 1.707 sec/batch
INFO:tensorflow:Step: 464, Accuracy: 0.656250, Loss: 5.268768, time: 1.529 sec/batch
INFO:tensorflow:Step: 467, Accuracy: 0.609375, Loss: 5.425957, time: 1.295 sec/batch
INFO:tensorflow:Step: 470, Accuracy: 0.656250, Loss: 5.150212, time: 1.234 sec/batch
INFO:tensorflow:Step: 473, Accuracy: 0.671875, Loss: 5.057487, time: 1.410 sec/batch
INFO:tensorflow:Step: 475, Accuracy: 0.609375, Loss: 5.351605, time: 1.561 sec/batch
INFO:tensorflow:Step: 478, Accuracy: 0.546875, Loss: 4.908569, time: 1.480 sec/batch
INFO:tensorflow:Step: 481, Accuracy: 0.656250, Loss: 5.264586, time: 1.426 sec/batch
INFO:tensorflow:Step: 484, Accuracy: 0.531250, Loss: 5.202728, time: 1.335 sec/batch
INFO:tensorflow:Step: 486, Accuracy: 0.625000, Loss: 5.256328, time: 1.311 sec/batch
INFO:tensorflow:Step: 489, Accuracy: 0.671875, Loss: 5.495539, time: 1.267 sec/batch
INFO:tensorflow:Step: 492, Accuracy: 0.609375, Loss: 5.100358, time: 1.246 sec/batch
INFO:tensorflow:Step: 495, Accuracy: 0.625000, Loss: 5.323066, time: 1.366 sec/batch
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.UnavailableError'>, 
not cropping. Imagesize: 256
not cropping. Imagesize: 256
not cropping. Imagesize: 256
not cropping. Imagesize: 256
Traceback (most recent call last):
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 321, in train
    tf.logging.info("Step: %d, Accuracy: %f, Loss: %f, time: %.3f sec/batch" %(step, sess.run(accuracy), loss_value, duration))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 372, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 636, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 708, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError: 
	 [[Node: conv4/weights/read_S4561 = _Recv[client_terminated=false, recv_device="/job:worker/replica:0/task:1/gpu:0", send_device="/job:ps/replica:0/task:0/cpu:0", send_device_incarnation=6764212793799932264, tensor_name="edge_1254_conv4/weights/read", tensor_type=DT_FLOAT, _device="/job:worker/replica:0/task:1/gpu:0"]()]]
	 [[Node: inception_v3/logits/logits/xw_plus_b_G1393 = _Recv[client_terminated=false, recv_device="/job:worker/replica:0/task:1/cpu:0", send_device="/job:worker/replica:0/task:1/gpu:0", send_device_incarnation=-51896661871583243, tensor_name="edge_2646_inception_v3/logits/logits/xw_plus_b", tensor_type=DT_FLOAT, _device="/job:worker/replica:0/task:1/cpu:0"]()]]
E0719 13:49:46.989499274    9508 tcp_client_posix.c:173]     failed to connect to 'ipv4:127.0.1.1:2228': socket error: connection refused
