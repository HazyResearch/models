I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['raiders1:2200']
INFO:tensorflow:Worker hosts are: ['raiders1:2201', 'raiders1:2202', 'raiders1:2203', 'raiders1:2204', 'raiders2:2205', 'raiders2:2206', 'raiders2:2207', 'raiders2:2208', 'raiders3:2209', 'raiders3:2210', 'raiders3:2211', 'raiders3:2212', 'raiders8:2213', 'raiders8:2214', 'raiders8:2215', 'raiders8:2216']
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: raiders1
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: raiders1
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.27  Thu Jun  9 18:53:27 PDT 2016
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 367.27.0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {raiders1:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2201, raiders1:2202, raiders1:2203, raiders1:2204, raiders2:2205, raiders2:2206, raiders2:2207, raiders2:2208, raiders3:2209, raiders3:2210, raiders3:2211, raiders3:2212, raiders8:2213, raiders8:2214, raiders8:2215, raiders8:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2201
INFO:tensorflow:Learning rate: 0.001000, momentum: 0.900000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 2
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 8
INFO:tensorflow:Tokens per step: 8
INFO:tensorflow:2016-07-26 13:37:47.745198 Supervisor
INFO:tensorflow:Restored model from /lfs/local/0/daniter/cg-snapshot/model.ckpt-399
INFO:tensorflow:got sessions! 2016-07-26 13:38:44.336526 
INFO:tensorflow:Started 3 queues for processing input data.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Step: 399, Loss: 5.720819, time: 18.545 sec/batch
INFO:tensorflow:Step: 400, Loss: 5.662608, time: 17.910 sec/batch
INFO:tensorflow:Step: 402, Loss: 5.206467, time: 15.150 sec/batch
INFO:tensorflow:Step: 404, Loss: 4.748652, time: 16.197 sec/batch
INFO:tensorflow:Step: 406, Loss: 5.044934, time: 11.600 sec/batch
INFO:tensorflow:Step: 408, Loss: 4.931831, time: 13.908 sec/batch
INFO:tensorflow:global_step/sec: 0.101176
INFO:tensorflow:Step: 410, Loss: 5.463477, time: 15.764 sec/batch
INFO:tensorflow:Step: 412, Loss: 5.002495, time: 16.301 sec/batch
INFO:tensorflow:Step: 414, Loss: 5.058845, time: 18.463 sec/batch
INFO:tensorflow:Step: 416, Loss: 4.941605, time: 15.090 sec/batch
INFO:tensorflow:Step: 418, Loss: 5.713041, time: 21.668 sec/batch
INFO:tensorflow:Step: 420, Loss: 5.634562, time: 16.148 sec/batch
INFO:tensorflow:Step: 422, Loss: 5.373936, time: 19.304 sec/batch
INFO:tensorflow:global_step/sec: 0.108304
INFO:tensorflow:Step: 424, Loss: 5.662445, time: 19.954 sec/batch
INFO:tensorflow:Step: 426, Loss: 6.090367, time: 20.170 sec/batch
INFO:tensorflow:Step: 428, Loss: 5.112163, time: 19.990 sec/batch
INFO:tensorflow:Step: 430, Loss: 5.480480, time: 20.679 sec/batch
INFO:tensorflow:Step: 432, Loss: 5.196681, time: 18.467 sec/batch
INFO:tensorflow:Step: 434, Loss: 5.300167, time: 19.836 sec/batch
INFO:tensorflow:global_step/sec: 0.100014
INFO:tensorflow:Step: 436, Loss: 5.217325, time: 15.392 sec/batch
INFO:tensorflow:Step: 438, Loss: 5.595324, time: 20.303 sec/batch
INFO:tensorflow:Step: 440, Loss: 4.944334, time: 16.779 sec/batch
INFO:tensorflow:Step: 442, Loss: 4.944171, time: 15.897 sec/batch
INFO:tensorflow:Step: 444, Loss: 5.383202, time: 18.045 sec/batch
INFO:tensorflow:Step: 446, Loss: 5.505866, time: 18.834 sec/batch
INFO:tensorflow:Step: 448, Loss: 5.425373, time: 18.542 sec/batch
INFO:tensorflow:global_step/sec: 0.116672
INFO:tensorflow:Step: 450, Loss: 5.317215, time: 18.698 sec/batch
INFO:tensorflow:Step: 452, Loss: 5.221597, time: 16.297 sec/batch
INFO:tensorflow:Step: 453, Loss: 5.564466, time: 19.420 sec/batch
INFO:tensorflow:global_step/sec: 0.050005
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:global_step/sec: 0
run-expr-32node.sh: line 23: 67890 Terminated              CUDA_VISIBLE_DEVICES='' bazel-bin/inception/imagenet_distributed_train --batch_size=16 --data_dir=/lfs/local/0/daniter/16node-data-$2 --job_name='worker' --task_id=$2 --ps_hosts='raiders1:2200' --worker_hosts='raiders1:2201,raiders1:2202,raiders1:2203,raiders1:2204,raiders2:2205,raiders2:2206,raiders2:2207,raiders2:2208,raiders3:2209,raiders3:2210,raiders3:2211,raiders3:2212,raiders8:2213,raiders8:2214,raiders8:2215,raiders8:2216' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
