DISPLAY "(null)" invalid; disabling X11 forwarding
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['raiders1:2228']
INFO:tensorflow:Worker hosts are: ['raiders1:2200', 'raiders1:2201', 'raiders3:2209', 'raiders3:2210']
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:43:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:43:00.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {raiders1:2228}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {raiders1:2200, raiders1:2201, raiders3:2209, localhost:2210}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2210
INFO:tensorflow:Learning rate: 0.010000, momentum: 0.750000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 4
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=4; total_num_replicas=4
INFO:tensorflow:Num nodes per compute groups: 1
INFO:tensorflow:Tokens per step: 1
INFO:tensorflow:2016-07-19 13:47:57.980490 Supervisor
INFO:tensorflow:got sessions!
INFO:tensorflow:Started 3 queues for processing input data.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3576 get requests, put_count=2565 evicted_count=1000 eviction_rate=0.389864 and unsatisfied allocation rate=0.590324
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Step: 399, Accuracy: 0.609375, Loss: 5.164156, time: 6.476 sec/batch
INFO:tensorflow:Step: 402, Accuracy: 0.625000, Loss: 5.677589, time: 1.962 sec/batch
INFO:tensorflow:Step: 406, Accuracy: 0.515625, Loss: 5.650886, time: 1.566 sec/batch
INFO:tensorflow:Step: 408, Accuracy: 0.562500, Loss: 5.430455, time: 1.724 sec/batch
INFO:tensorflow:Step: 412, Accuracy: 0.484375, Loss: 5.349771, time: 2.849 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1016 evicted_count=1000 eviction_rate=0.984252 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 415, Accuracy: 0.593750, Loss: 5.648292, time: 2.098 sec/batch
INFO:tensorflow:Step: 419, Accuracy: 0.578125, Loss: 5.291265, time: 1.825 sec/batch
INFO:tensorflow:Step: 422, Accuracy: 0.437500, Loss: 5.729081, time: 2.578 sec/batch
INFO:tensorflow:Step: 426, Accuracy: 0.656250, Loss: 5.254829, time: 1.830 sec/batch
INFO:tensorflow:Step: 429, Accuracy: 0.593750, Loss: 5.256220, time: 2.721 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1025 evicted_count=1000 eviction_rate=0.97561 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 432, Accuracy: 0.578125, Loss: 5.299582, time: 1.986 sec/batch
INFO:tensorflow:Step: 436, Accuracy: 0.625000, Loss: 5.109637, time: 2.043 sec/batch
INFO:tensorflow:Step: 438, Accuracy: 0.640625, Loss: 5.374008, time: 1.518 sec/batch
INFO:tensorflow:Step: 441, Accuracy: 0.656250, Loss: 5.202773, time: 1.534 sec/batch
INFO:tensorflow:Step: 444, Accuracy: 0.593750, Loss: 5.366652, time: 1.402 sec/batch
INFO:tensorflow:Step: 447, Accuracy: 0.546875, Loss: 5.607708, time: 1.471 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1044 evicted_count=1000 eviction_rate=0.957854 and unsatisfied allocation rate=0
INFO:tensorflow:Step: 450, Accuracy: 0.609375, Loss: 5.240608, time: 1.547 sec/batch
INFO:tensorflow:Step: 454, Accuracy: 0.656250, Loss: 5.321681, time: 1.892 sec/batch
INFO:tensorflow:Step: 456, Accuracy: 0.656250, Loss: 5.265121, time: 1.375 sec/batch
INFO:tensorflow:Step: 459, Accuracy: 0.593750, Loss: 5.107242, time: 1.868 sec/batch
INFO:tensorflow:Step: 462, Accuracy: 0.640625, Loss: 5.365840, time: 1.445 sec/batch
INFO:tensorflow:Step: 465, Accuracy: 0.640625, Loss: 5.136831, time: 1.826 sec/batch
INFO:tensorflow:Step: 469, Accuracy: 0.656250, Loss: 5.147495, time: 1.705 sec/batch
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3579 get requests, put_count=4415 evicted_count=2000 eviction_rate=0.453001 and unsatisfied allocation rate=0.347304
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 871 to 958
INFO:tensorflow:Step: 473, Accuracy: 0.593750, Loss: 5.297996, time: 1.474 sec/batch
INFO:tensorflow:Step: 476, Accuracy: 0.515625, Loss: 5.155689, time: 1.548 sec/batch
INFO:tensorflow:Step: 479, Accuracy: 0.625000, Loss: 4.980701, time: 1.472 sec/batch
INFO:tensorflow:Step: 482, Accuracy: 0.671875, Loss: 5.289495, time: 1.415 sec/batch
INFO:tensorflow:Step: 485, Accuracy: 0.656250, Loss: 5.166413, time: 1.482 sec/batch
INFO:tensorflow:Step: 488, Accuracy: 0.546875, Loss: 5.148824, time: 1.276 sec/batch
INFO:tensorflow:Step: 491, Accuracy: 0.625000, Loss: 5.282525, time: 1.651 sec/batch
INFO:tensorflow:Step: 494, Accuracy: 0.609375, Loss: 5.101059, time: 1.464 sec/batch
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.UnavailableError'>, 
E0719 13:49:47.132418787   90610 tcp_client_posix.c:173]     failed to connect to 'ipv4:172.24.75.13:2228': socket error: connection refused
not cropping. Imagesize: 256
not cropping. Imagesize: 256
not cropping. Imagesize: 256
not cropping. Imagesize: 256
Traceback (most recent call last):
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 321, in train
    tf.logging.info("Step: %d, Accuracy: %f, Loss: %f, time: %.3f sec/batch" %(step, sess.run(accuracy), loss_value, duration))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 372, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 636, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 708, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError: 
	 [[Node: mixed_17x17x768b/branch7x7dbl/Conv_3/weights/read_S4681 = _Recv[client_terminated=false, recv_device="/job:worker/replica:0/task:3/gpu:0", send_device="/job:ps/replica:0/task:0/cpu:0", send_device_incarnation=6764212793799932264, tensor_name="edge_214_mixed_17x17x768b/branch7x7dbl/Conv_3/weights/read", tensor_type=DT_FLOAT, _device="/job:worker/replica:0/task:3/gpu:0"]()]]
	 [[Node: Mean_G2445 = _Recv[client_terminated=false, recv_device="/job:worker/replica:0/task:3/cpu:0", send_device="/job:worker/replica:0/task:3/gpu:0", send_device_incarnation=-4792758851867127581, tensor_name="edge_2655_Mean", tensor_type=DT_FLOAT, _device="/job:worker/replica:0/task:3/cpu:0"]()]]
