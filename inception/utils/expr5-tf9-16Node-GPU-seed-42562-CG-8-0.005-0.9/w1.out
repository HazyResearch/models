INFO:tensorflow:PS hosts are: ['localhost:2228']
INFO:tensorflow:Worker hosts are: ['localhost:2201', 'localhost:2202', 'localhost:2203', 'localhost:2204', 'localhost:2205', 'localhost:2206', 'localhost:2207', 'localhost:2208', 'localhost:2209', 'localhost:2210', 'localhost:2211', 'localhost:2212', 'localhost:2213', 'localhost:2214', 'localhost:2215', 'localhost:2216']
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2228}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2201, localhost:2202, localhost:2203, localhost:2204, localhost:2205, localhost:2206, localhost:2207, localhost:2208, localhost:2209, localhost:2210, localhost:2211, localhost:2212, localhost:2213, localhost:2214, localhost:2215, localhost:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2201
INFO:tensorflow:Learning rate: 0.005000, momentum: 0.900000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 8
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 2
INFO:tensorflow:Tokens per step: 2
INFO:tensorflow:2016-07-20 01:52:23.636138 Supervisor
INFO:tensorflow:Restored model from /lfs/local/0/daniter/cg-snapshot/model.ckpt-399
run-expr-16node.sh: line 23: 25611 Terminated              CUDA_VISIBLE_DEVICES='' bazel-bin/inception/imagenet_distributed_train --batch_size=16 --data_dir=/lfs/local/0/daniter/imagenet-8-$2 --job_name='worker' --task_id=$2 --ps_hosts='localhost:2228' --worker_hosts='localhost:2201,localhost:2202,localhost:2203,localhost:2204,localhost:2205,localhost:2206,localhost:2207,localhost:2208,localhost:2209,localhost:2210,localhost:2211,localhost:2212,localhost:2213,localhost:2214,localhost:2215,localhost:2216' --initial_learning_rate=$3 --momentum=$4 --sync=True --compute_groups=$5
