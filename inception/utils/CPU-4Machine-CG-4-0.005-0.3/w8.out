DISPLAY "(null)" invalid; disabling X11 forwarding
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['raiders1:2200']
INFO:tensorflow:Worker hosts are: ['raiders1:2201', 'raiders1:2202', 'raiders1:2203', 'raiders1:2204', 'raiders2:2205', 'raiders2:2206', 'raiders2:2207', 'raiders2:2208', 'raiders3:2209', 'raiders3:2210', 'raiders3:2211', 'raiders3:2212', 'raiders8:2213', 'raiders8:2214', 'raiders8:2215', 'raiders8:2216']
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: raiders2
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: raiders2
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.93  Tue Apr  5 18:18:24 PDT 2016
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.1) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.93.0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {raiders1:2200}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {raiders1:2201, raiders1:2202, raiders1:2203, raiders1:2204, raiders2:2205, raiders2:2206, raiders2:2207, localhost:2208, raiders3:2209, raiders3:2210, raiders3:2211, raiders3:2212, raiders8:2213, raiders8:2214, raiders8:2215, raiders8:2216}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2208
INFO:tensorflow:Learning rate: 0.005000, momentum: 0.300000
INFO:tensorflow:Sync mode!!!!!!
INFO:tensorflow:Compute groups : 4
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=16; total_num_replicas=16
INFO:tensorflow:Num nodes per compute groups: 4
INFO:tensorflow:Tokens per step: 4
INFO:tensorflow:2016-07-26 06:06:04.112641 Supervisor
INFO:tensorflow:got sessions! 2016-07-26 06:06:19.241240 
INFO:tensorflow:Started 3 queues for processing input data.
INFO:tensorflow:Step: 399, Loss: 6.511412, time: 33.330 sec/batch
INFO:tensorflow:Step: 399, Loss: 5.581910, time: 21.885 sec/batch
INFO:tensorflow:Step: 406, Loss: 5.696696, time: 14.925 sec/batch
INFO:tensorflow:Step: 409, Loss: 5.309747, time: 14.672 sec/batch
INFO:tensorflow:Step: 413, Loss: 5.340160, time: 13.926 sec/batch
INFO:tensorflow:Step: 417, Loss: 5.816123, time: 15.518 sec/batch
INFO:tensorflow:Step: 421, Loss: 5.188005, time: 17.858 sec/batch
INFO:tensorflow:Step: 426, Loss: 5.559348, time: 15.567 sec/batch
INFO:tensorflow:Step: 430, Loss: 5.537517, time: 15.263 sec/batch
INFO:tensorflow:Step: 434, Loss: 5.264713, time: 16.993 sec/batch
INFO:tensorflow:Step: 438, Loss: 5.513956, time: 15.615 sec/batch
INFO:tensorflow:Step: 442, Loss: 5.236849, time: 16.007 sec/batch
INFO:tensorflow:Step: 447, Loss: 5.562509, time: 14.091 sec/batch
INFO:tensorflow:Step: 452, Loss: 5.186546, time: 23.205 sec/batch
INFO:tensorflow:Step: 457, Loss: 5.559799, time: 17.081 sec/batch
INFO:tensorflow:Step: 463, Loss: 4.904139, time: 23.509 sec/batch
INFO:tensorflow:Step: 469, Loss: 5.289756, time: 21.570 sec/batch
INFO:tensorflow:Step: 475, Loss: 5.273013, time: 17.842 sec/batch
INFO:tensorflow:Step: 480, Loss: 5.564553, time: 15.615 sec/batch
INFO:tensorflow:Step: 484, Loss: 5.092080, time: 30.242 sec/batch
INFO:tensorflow:Step: 491, Loss: 5.219961, time: 27.661 sec/batch
INFO:tensorflow:Step: 497, Loss: 5.033082, time: 28.738 sec/batch
INFO:tensorflow:Step: 504, Loss: 5.980230, time: 38.940 sec/batch
INFO:tensorflow:Step: 511, Loss: 5.139627, time: 41.027 sec/batch
INFO:tensorflow:Step: 519, Loss: 4.985299, time: 34.167 sec/batch
INFO:tensorflow:Step: 523, Loss: 5.055416, time: 40.435 sec/batch
INFO:tensorflow:Step: 527, Loss: 5.594376, time: 33.815 sec/batch
INFO:tensorflow:Step: 531, Loss: 5.317510, time: 25.709 sec/batch
INFO:tensorflow:Step: 535, Loss: 5.552222, time: 18.721 sec/batch
INFO:tensorflow:Step: 539, Loss: 5.170195, time: 22.713 sec/batch
INFO:tensorflow:Step: 543, Loss: 5.401875, time: 19.935 sec/batch
INFO:tensorflow:Step: 546, Loss: 5.492537, time: 29.565 sec/batch
INFO:tensorflow:Step: 551, Loss: 5.155005, time: 30.975 sec/batch
INFO:tensorflow:Step: 554, Loss: 5.518317, time: 28.490 sec/batch
INFO:tensorflow:Step: 559, Loss: 5.345105, time: 29.526 sec/batch
INFO:tensorflow:Step: 562, Loss: 5.026700, time: 28.706 sec/batch
INFO:tensorflow:Step: 566, Loss: 5.424639, time: 33.569 sec/batch
INFO:tensorflow:Step: 570, Loss: 5.328718, time: 24.774 sec/batch
INFO:tensorflow:Step: 574, Loss: 5.253082, time: 26.106 sec/batch
INFO:tensorflow:Step: 578, Loss: 5.322519, time: 29.643 sec/batch
INFO:tensorflow:Step: 582, Loss: 5.320581, time: 27.432 sec/batch
INFO:tensorflow:Step: 586, Loss: 5.288262, time: 23.145 sec/batch
INFO:tensorflow:Step: 590, Loss: 5.350762, time: 35.810 sec/batch
Traceback (most recent call last):
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 69, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/afs/cs.stanford.edu/u/daniter/tf-test/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py", line 329, in train
    loss_value, step = sess.run([train_op, global_step])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 372, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 636, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 708, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError
