I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['localhost:2228']
INFO:tensorflow:Worker hosts are: ['raiders1:2200', 'raiders1:2201', 'raiders3:2209', 'raiders3:2210']
E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: raiders1
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: raiders1
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 367.27
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.27  Thu Jun  9 18:53:27 PDT 2016
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 367.27
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 367.27
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2228}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {raiders1:2200, raiders1:2201, raiders3:2209, raiders3:2210}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2228
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[543][0.00016142562 0.00051636138...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[543][0.00016107972 0.00051223481...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[545][0.00063873804 0.0002201098...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[546][0.00062463526 0.0002381001...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[547][0.00063198234 -0.00019834595...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[548][0.00057281589 -0.00021486428...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[549][0.00021211136 5.4284319e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[550][2.1980262e-05 0.00011743297...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[551][0.00029431022 -0.00020550407...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[552][9.1996379e-05 -0.00029492023...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[553][-4.043919e-06 8.9479494e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[554][0.00024565417 0.00017538245...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[555][0.00064328365 -3.98676e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[556][0.00044323807 1.201994e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[557][3.38085e-05 -6.8656729e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[557][0.00016357978 -5.2194344e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[559][0.00021205554 0.00019965519...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[560][0.00010085813 0.00014330071...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[561][-5.3761392e-05 0.00022351545...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[562][0.00015875419 0.00030103279...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[563][0.00010305377 -0.00011293615...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[564][0.0001472728 -0.00024989626...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[565][-0.00017720714 -7.510274e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[566][7.2731054e-05 0.00021189408...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[567][3.1880045e-05 0.00020078933...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[568][-0.00024326486 -0.00032788911...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[569][-0.00023751742 -5.6517863e-05...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[570][-4.1846215e-05 0.00048915262...]
I tensorflow/core/kernels/logging_ops.cc:79] ~~~~~ daniter~~~ GLobalstep:[571][6.3976826e-05 0.00021078979...]
run-ps-4node.sh: line 21: 34897 Terminated              CUDA_VISIBLE_DEVICES='' bazel-bin/inception/imagenet_distributed_train --batch_size=64 --data_dir=/lfs/local/0/daniter/imagenet-8 --job_name='ps' --task_id=0 --ps_hosts='localhost:2228' --worker_hosts='raiders1:2200,raiders1:2201,raiders3:2209,raiders3:2210' --initial_learning_rate=$1 --momentum=$2 --sync=True --compute_groups=$3
